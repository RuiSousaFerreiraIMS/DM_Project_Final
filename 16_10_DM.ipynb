{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ab9cff",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"border: none; padding-right: 20px;\">\n",
    "      <img src=\"logo_uni.png\" width=\"300\" style=\"margin: 0; padding: 0;\">\n",
    "    </td>\n",
    "    <td style=\"border: none; vertical-align: middle;\">\n",
    "      <h1 style=\"margin: 0;\">Airline Customer Segmentation</h1>\n",
    "      <p style=\"margin: 0; font-size: 18px;\">Master in Data Science - 2025/26</p>\n",
    "      <p style=\"margin: 0; font-style: italic;\">Developed by: <b>[Alexandre Coelho, 20250475], [Bruna Sousa, 20250526], [Rui Ferreira, 20250473] \n",
    "</b></p>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "id": "bc762774",
   "metadata": {},
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mpl_colors\n",
    "from narwhals.stable.v1 import Datetime\n",
    "from sklearn.cluster import KMeans, HDBSCAN, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import functions as func\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from minisom import MiniSom\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import plotly.express as px\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82e833ed",
   "metadata": {},
   "source": [
    "try:\n",
    "    from functions import *\n",
    "    print(\"SUCCESS: Custom functions loaded correctly from 'my_functions.py'.\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: Could not find 'my_functions.py'. Make sure the file is in the same folder as this notebook.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dcd8844bd8f5b21b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Business Understanding](#business-understanding)\n",
    "- [Data Understanding](#data-understanding)\n",
    "  - [Customer Database](#customer-database)\n",
    "    - [Reading the data](#reading-the-data)\n",
    "    - [Metadata](#metadata)\n",
    "    - [Initial Analysis](#initial-analysis)\n",
    "    - [Data Quality Checks](#data-quality-checks)\n",
    "  - [Flights Database](#flights-database)\n",
    "    - [Reading the data](#reading-the-data-1)\n",
    "    - [Metadata](#metadata-1)\n",
    "    - [Initial Analysis](#initial-analysis-1)\n",
    "    - [Data Quality Checks](#data-quality-checks-1)\n",
    "- [Data Preparation](#data-preparation)\n",
    "  - [Customers Database](#customers-database)\n",
    "    - [Data Types](#data-types)\n",
    "    - [Duplicates](#duplicates)\n",
    "    - [Missing Values](#missing-values)\n",
    "    - [Coherence Check](#coherence-check)\n",
    "  - [Flights Database](#flights-database-1)\n",
    "    - [Data Types](#data-types-1)\n",
    "    - [Duplicates](#duplicates-1)\n",
    "    - [Coherence Check](#coherence-check-1)\n",
    "    - [Coherence Check on both databases](#coherence-check-on-both-databases)\n",
    "- [Data Exploration](#data-exploration)\n",
    "  - [Customer](#customer)\n",
    "  - [Distributions of Categorical Features](#distributions-of-categorical-features)\n",
    "  - [Distribution of Numerical Features](#distribution-of-numerical-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86431ca",
   "metadata": {},
   "source": [
    "## 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb6eb7",
   "metadata": {},
   "source": [
    "AIAI aims to use customer data to understand their behaviors, with the goal of improving satisfaction, customer value, and profitability. The main challenge is to segment customers based on their travel habits and loyalty, enabling the creation of personalized marketing and optimized services. The project aims to transform these analytical findings into actionable business strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d53a7",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5cd21",
   "metadata": {},
   "source": [
    "### 2.1 Customer Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f7c08",
   "metadata": {},
   "source": [
    "#### 2.1.1 Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7acac9c",
   "metadata": {},
   "source": [
    "customer_data = pd.read_csv(\"DM_AIAI_CustomerDB.csv\",index_col=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aae0ae7e",
   "metadata": {},
   "source": [
    "#### 2.1.2 Metadata\n",
    "- *Loyalty#* - Unique customer identifier for loyalty program members\n",
    "- *First Name* - Customer's first name\n",
    "- *Last Name* -\tCustomer's last name\n",
    "- *Customer Name* - Customer's full name (concatenated)\n",
    "- *Country* - Customer's country of residence\n",
    "- *Province or State* - Customer's province or state\n",
    "- *City* - Customer's city of residence\n",
    "- *Latitude* - Geographic latitude coordinate of customer location\n",
    "- *Longitude* - Geographic longitude coordinate of customer location\n",
    "- *Postal code* - Customer's postal/ZIP code\n",
    "- *Gender* - Customer's gender\n",
    "- *Education* - Customer's highest education level (Bachelor, College, etc.)\n",
    "- *Location Code*- Urban/Suburban/Rural classification of customer residence\n",
    "- *Income* - Customer's annual income\n",
    "- *Marital Status* - Customer's marital status (Married, Single, Divorced)\n",
    "- *LoyaltyStatus* - Current tier status in loyalty program (Star > Nova > Aurora)\n",
    "- *EnrollmentDateOpening* - Date when customer joined the loyalty program\n",
    "- *CancellationDate* - Date when customer left the program\n",
    "- *Customer Lifetime Value* - Total calculated monetary value of customer relationship\n",
    "- *EnrollmentType* - Method of joining loyalty program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3296d483",
   "metadata": {},
   "source": [
    "#### 2.1.3 Initial Analysis\n",
    "General idea of the data structure, column names and types of values each variable contains."
   ]
  },
  {
   "cell_type": "code",
   "id": "b4ebd035",
   "metadata": {},
   "source": [
    "customer = customer_data.copy()\n",
    "customer.head(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e3f3526",
   "metadata": {},
   "source": [
    "print(f\"Numbers of lines and columns: {customer.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88454845",
   "metadata": {},
   "source": [
    "customer.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd68964b",
   "metadata": {},
   "source": [
    "customer.describe(include=\"all\").T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f80233df",
   "metadata": {},
   "source": [
    "#### 2.1.4 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "id": "0f654792",
   "metadata": {},
   "source": [
    "customer.replace(\"\", np.nan, inplace=True)\n",
    "customer.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a7b2ecbd",
   "metadata": {},
   "source": [
    "We have 20 customers without income data, 20 customers without Customer Lifetime Value data and 14611 customers without CancellationDate data."
   ]
  },
  {
   "cell_type": "code",
   "id": "244f3b0c",
   "metadata": {},
   "source": [
    "customer.duplicated().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e113959d",
   "metadata": {},
   "source": [
    "We have no duplicated rows in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e27f6",
   "metadata": {},
   "source": [
    "### 2.2 Flights Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31fd46a",
   "metadata": {},
   "source": [
    "#### 2.2.1 Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "90ac3f0b",
   "metadata": {},
   "source": [
    "flight_data = pd.read_csv(\"DM_AIAI_FlightsDB.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "02626be0",
   "metadata": {},
   "source": [
    "#### 2.2.2 Metadata\n",
    "- *Variable* - Description\n",
    "- *Loyalty#* - Unique customer identifier linking to CustomerDB\n",
    "- *Year* -\tYear of flight activity record\n",
    "- *Month* - Month of flight activity record (1-12)\n",
    "- *YearMonthDate* - First day of the month for the activity period\n",
    "- *NumFlights* - Total number of flights taken by customer in the month\n",
    "- *NumFlightsWithCompanions* - Number of flights where customer traveled with companions\n",
    "- *DistanceKM* - Total distance traveled in kilometers for the month\n",
    "- *PointsAccumulated* - Loyalty points earned by customer during the month\n",
    "- *PointsRedeemed* - Loyalty points spent/redeemed by customer during the month\n",
    "- *DollarCostPointsRedeemed* - Dollar value of points redeemed during the month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a885992",
   "metadata": {},
   "source": [
    "#### 2.2.3 Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a2e2d",
   "metadata": {},
   "source": [
    "General idea of the data structure, column names and types of values each variable contains."
   ]
  },
  {
   "cell_type": "code",
   "id": "22bb0faa",
   "metadata": {},
   "source": [
    "flight = flight_data.copy()\n",
    "flight.head(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb234b96",
   "metadata": {},
   "source": [
    "print(f\"Numbers of lines and columns: {flight.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9c26060",
   "metadata": {},
   "source": [
    "flight.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86fc4cb8",
   "metadata": {},
   "source": [
    "flight.describe(include=\"all\").T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef08e5fc",
   "metadata": {},
   "source": [
    "#### 2.2.4 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "id": "b33fcef7",
   "metadata": {},
   "source": [
    "flight.replace(\"\", np.nan, inplace=True)\n",
    "flight.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6bf24c3",
   "metadata": {},
   "source": [
    "We have no missing data."
   ]
  },
  {
   "cell_type": "code",
   "id": "64911543",
   "metadata": {},
   "source": [
    "flight.duplicated().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "675734be",
   "metadata": {},
   "source": [
    "We have 2903 duplicated rowns in our data, that we will look at later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ca150",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15425152",
   "metadata": {},
   "source": [
    "### 3.1 Customers Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1950dec",
   "metadata": {},
   "source": [
    "#### 3.1.1 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "id": "9cbf53ed",
   "metadata": {},
   "source": [
    "customer.dtypes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cf64fa93",
   "metadata": {},
   "source": [
    "The Enrollment Date Opening and Cancellation Dates can be converted to datetime type."
   ]
  },
  {
   "cell_type": "code",
   "id": "d5de85d9",
   "metadata": {},
   "source": [
    "customer[\"EnrollmentDateOpening\"] = pd.to_datetime(customer[\"EnrollmentDateOpening\"])\n",
    "customer[\"CancellationDate\"] = pd.to_datetime(customer[\"CancellationDate\"], errors=\"coerce\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c731aa6e",
   "metadata": {},
   "source": [
    "#### 3.1.2 Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23602b3f209ba136",
   "metadata": {},
   "source": [
    "To use the 'Loyalty#' column as the dataframe's index, it was essential to first confirm that it contained only unique values. An index acts as a primary key for data retrieval, and duplicate entries would make this unreliable.\n",
    "\n",
    "Upon inspection, some 'Loyalty#' IDs were found to be duplicated. Since there was no clear way to determine which entry represented the true customer record (the \"source of truth\"), the most robust decision was to remove all records associated with these ambiguous IDs. This data cleansing step ensures the integrity of the dataset, leaving only customers with a single, unique 'Loyalty#' identifier, which can now be reliably set as the index."
   ]
  },
  {
   "cell_type": "code",
   "id": "dd182a3f",
   "metadata": {},
   "source": [
    "duplicated_loyalty = customer_data.duplicated(subset=['Loyalty#'], keep=False)\n",
    "duplicated_loyalty_list = customer_data[duplicated_loyalty]['Loyalty#'].unique()\n",
    "print(f\"Duplicated Loyaltys {len(duplicated_loyalty_list)}\")\n",
    "customer = customer[customer['Loyalty#'].isin(duplicated_loyalty_list) == False]\n",
    "print(f\"For the initial customer data we have {len(customer_data)} records.\\n\"\n",
    "      f\"We identified {len(duplicated_loyalty_list)} 'Loyalty#' IDs that were duplicated or appears repeatedly.\\n\"\n",
    "      f\"So the final len of the data set is {len(customer)}.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae6549f6",
   "metadata": {},
   "source": [
    "customer.set_index(\"Loyalty#\", inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3518aed4",
   "metadata": {},
   "source": [
    "#### 3.1.3 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "id": "2cff274c",
   "metadata": {},
   "source": [
    "customer[customer[\"Income\"].isna()].tail(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5366d278",
   "metadata": {},
   "source": [
    "The customers with missing income information also have a Customer Lifetime Value equal to 0, which we believe is because their cancellation date is the same as their enrollment date, and it has no value for the company."
   ]
  },
  {
   "cell_type": "code",
   "id": "fd513dc8",
   "metadata": {},
   "source": [
    "customer_NaN_income = customer[\"Income\"].isna().mean() * 100\n",
    "print(f\"The percentage of customers with missing data about income is {customer_NaN_income:.2f} %.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "015ae6ca",
   "metadata": {},
   "source": [
    "Because the percentage of missing data about income is 0.12 %, it is safe to remove this rows."
   ]
  },
  {
   "cell_type": "code",
   "id": "d4364cf9",
   "metadata": {},
   "source": [
    "customer = customer.dropna(subset=['Income'])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c06b9cb",
   "metadata": {},
   "source": [
    "#### 3.1.4 Coherence Check"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a61361a",
   "metadata": {},
   "source": [
    "# Number of customers with available values in cancellation date\n",
    "total_cancel_dates = len(customer[customer[\"CancellationDate\"].notna()])\n",
    "print(f\"Number of available cancellation dates: {total_cancel_dates} ({((total_cancel_dates/len(customer))*100):.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d6de4be",
   "metadata": {},
   "source": [
    "Missing values in the CancellationDate column (which affects 86.45% of the customer base) are assumed to represent customers who have never officially terminated their loyalty membership. "
   ]
  },
  {
   "cell_type": "code",
   "id": "84ff543a",
   "metadata": {},
   "source": [
    "# Number of customers with cancelation date before the enrollment date\n",
    "incoherent_cancel_dates = len(customer[customer['CancellationDate'] < customer['EnrollmentDateOpening']])\n",
    "print(f\"Number of incoherent dates: {incoherent_cancel_dates} ({((incoherent_cancel_dates/total_cancel_dates)*100):.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acadaa7f",
   "metadata": {},
   "source": [
    "The 199 incoherent dates (CancellationDate < EnrollmentDateOpening) strongly suggest a business scenario where members re-enrolled in the loyalty program. It is possible that the CancellationDate reflects an old membership end,  while EnrollmentDateOpening records the start of their current re-activated membership.\n",
    "\n",
    "This group represents a valuable segment of returned customers,  which we should give special attention during the segmentation phase. "
   ]
  },
  {
   "cell_type": "code",
   "id": "83d48cc9",
   "metadata": {},
   "source": [
    "# Number of incoherent enrollment type \n",
    "cust_2021_promo = customer[customer[\"EnrollmentType\"] == \"2021 Promotion\"].copy()\n",
    "cust_2021_promo[\"EnrollmentYear\"] = cust_2021_promo[\"EnrollmentDateOpening\"].dt.year\n",
    "incoherent_enrollment_type = cust_2021_promo[cust_2021_promo[\"EnrollmentYear\"] !=2021.0]\n",
    "print(f\"Number of incoherent enrollment type (enrollment out of 2021): {len(incoherent_enrollment_type)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4addc358",
   "metadata": {},
   "source": [
    "This check was performed to verify if the categorical feature \"2021 Promotion\" in EnrollmentType was chronologically coherent with the customer's EnrollmentDateOpening. The result shows that 172 of customers tagged with the \"2021 Promotion\" were registered in earlier years (2015, 2017,...).\n",
    "\n",
    "The EnrollmentType variable remains useful for demographic/psychographic segmentation (identifying customers sensitive to incentives), but its value cannot be strictly relied upon for calculating customer longevity."
   ]
  },
  {
   "cell_type": "code",
   "id": "0a778318",
   "metadata": {},
   "source": [
    "# Number of customer's names that don´t correspond to concatenation of first name and last name\n",
    "coherent_names = ( customer[\"First Name\"].str.strip()+\" \"+customer[\"Last Name\"].str.strip())\n",
    "incoherent_names_condition = (customer[\"Customer Name\"].str.strip() != coherent_names.str.strip())\n",
    "incoherent_names = customer[incoherent_names_condition]\n",
    "print(f\"Number of unmatched customer names: {len(incoherent_names)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cbeb23a0",
   "metadata": {},
   "source": [
    "Furthermore, comparing Customer Name against the concatenation of First Name and Last Name confirmed zero inconsistencies, demonstrating the perfect integrity of the customer identification fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f86ab",
   "metadata": {},
   "source": [
    "### 3.2 Flights Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ce9ad",
   "metadata": {},
   "source": [
    "#### 3.2.1 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "id": "448b4870",
   "metadata": {},
   "source": [
    "flight.dtypes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e890ef23",
   "metadata": {},
   "source": [
    "We decided to change the data types of variables NumFlights, NumFlightsWithCompanions, PointsAccumulated and PointsRedeemed to integers because these variables are discrete.\n",
    "Also, the YearMonthDate variable can be converted to datetime type."
   ]
  },
  {
   "cell_type": "code",
   "id": "662ab2f3",
   "metadata": {},
   "source": [
    "flight['YearMonthDate'] = pd.to_datetime(flight['YearMonthDate'], errors='coerce')\n",
    "\n",
    "columns_to_convert = [\"NumFlights\", \"NumFlightsWithCompanions\", \"PointsAccumulated\", \"PointsRedeemed\"]\n",
    "flight[columns_to_convert] = flight[columns_to_convert].astype(int)\n",
    "print(flight[columns_to_convert].dtypes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f3824234",
   "metadata": {},
   "source": [
    "#### 3.2.2 Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7675132fd531bc0",
   "metadata": {},
   "source": [
    "Following the removal of ambiguous 'Loyalty#' IDs from the customer dataset, the same filtering was applied to the flight dataset. This step was crucial for maintaining referential integrity, as it ensures that the flight data only contains records for customers who are verifiably present in the customer data."
   ]
  },
  {
   "cell_type": "code",
   "id": "46e972e8",
   "metadata": {},
   "source": [
    "flight = flight[flight['Loyalty#'].isin(duplicated_loyalty_list) == False]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3570d3c",
   "metadata": {},
   "source": [
    "flight.duplicated().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "13fad9bf0acce6bc",
   "metadata": {},
   "source": [
    "Interestingly, this action also resolved all duplicate issues within the flight dataset, indicating that the duplicated entries were tied to the same problematic 'Loyalty#' IDs. This clean-up ensures both datasets are now consistent and aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ec12e",
   "metadata": {},
   "source": [
    "#### 3.2.3 Coherence Checks"
   ]
  },
  {
   "cell_type": "code",
   "id": "8f44dc32",
   "metadata": {},
   "source": [
    "# Number of flights uncoherent\n",
    "print(f\"Number of uncoherent number of flights: {len(flight[flight[\"NumFlightsWithCompanions\"] > flight[\"NumFlights\"]])}\")\n",
    "\n",
    "# Number of flights with uncoherent data of DistanceKM\n",
    "print(f\"Number of uncoherent number of KMs: {len(flight[flight[\"DistanceKM\"] < flight[\"NumFlights\"]])}\")\n",
    "\n",
    "# Number of points accumulated with 0 KM travelled\n",
    "incoherent_points_condition = (flight[\"PointsAccumulated\"] >0) & (flight[\"DistanceKM\"] == 0)\n",
    "incoherent_points = flight[incoherent_points_condition]\n",
    "print(f\"Number of incoherent points accumulated: {len(incoherent_points)}\")\n",
    "\n",
    "# Number of incoherent points redeemed or dollar cost points redeemed\n",
    "incoherent_dollars_condition = (flight[\"PointsRedeemed\"]>0) & (flight[\"DollarCostPointsRedeemed\"]==0) | (flight[\"PointsRedeemed\"]==0) & (flight[\"DollarCostPointsRedeemed\"]>0)\n",
    "incoherent_dollars = flight[incoherent_dollars_condition]\n",
    "print(f\"Number of incoherent dollars redeemed: {len(incoherent_dollars)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f4fb7e2c",
   "metadata": {},
   "source": [
    "The flight activity data demonstrates high internal coherence, with zero records showing logical inconsistencies between flight counts, distance traveled, point accumulation and dollar cost of points redeemed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026bf61",
   "metadata": {},
   "source": [
    "### 3.3 Coherence Check on both databases"
   ]
  },
  {
   "cell_type": "code",
   "id": "530b29dd",
   "metadata": {},
   "source": [
    "# Number of incoherent customers flying after customer cancelling the membership\n",
    "cust_cancelled = customer[customer[\"CancellationDate\"].notna()].copy()\n",
    "\n",
    "merged_flights_cust_cancel = pd.merge(\n",
    "    customer[customer[\"CancellationDate\"].notna()][[\"CancellationDate\", \"EnrollmentDateOpening\"]],\n",
    "    flight[[\"Loyalty#\", \"YearMonthDate\", \"NumFlights\"]],\n",
    "    left_index=True, right_on= \"Loyalty#\", how=\"inner\"\n",
    ")\n",
    "\n",
    "flights_condition1 = (\n",
    "    (merged_flights_cust_cancel[\"YearMonthDate\"]> merged_flights_cust_cancel[\"CancellationDate\"]) &\n",
    "    (merged_flights_cust_cancel[\"NumFlights\"]>0) &\n",
    "    (merged_flights_cust_cancel[\"EnrollmentDateOpening\"]<=merged_flights_cust_cancel[\"CancellationDate\"])\n",
    ")\n",
    "\n",
    "flights1 = merged_flights_cust_cancel[flights_condition1]\n",
    "print(f\"Number of incoherent customers flying after customer cancelling the membership: {flights1[\"Loyalty#\"].nunique()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d813c03",
   "metadata": {},
   "source": [
    "This test verified if any customer registered flight activity after their official cancellation date without having subsequently re-enrolled in the loyalty program. The results showed zero unique customers exhibiting this true logical incoherence. The previously observed post-cancellation activity is fully justified by customer re-enrollment, meaning the old CancellationDate simply serves as a historical record rather than a current status flag."
   ]
  },
  {
   "cell_type": "code",
   "id": "6e9ddaa3",
   "metadata": {},
   "source": [
    "customer[\"CancellationDate\"] = customer[\"CancellationDate\"].fillna(pd.Timestamp(\"1904-01-01\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3b2ed474",
   "metadata": {},
   "source": [
    "dizer que agora sim mudamos o type do cancellation date "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7578a",
   "metadata": {},
   "source": [
    "## 4. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85c96d",
   "metadata": {},
   "source": [
    "### 4.1 Customer Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08915246",
   "metadata": {},
   "source": [
    "#### 4.1.1 Distribution of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "id": "23fb24d8",
   "metadata": {},
   "source": [
    "\n",
    "categorical_customer = [\"Gender\", \"Education\", \"Marital Status\", \"LoyaltyStatus\", \"EnrollmentType\", \"Location Code\",\"Country\"]\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i, col in enumerate(categorical_customer, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    sns.countplot(x=col, data=customer, order=customer[col].value_counts().index)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ccfdaf88",
   "metadata": {},
   "source": [
    "\n",
    "From these visualizations, we observe that the dataset shows no meaningful variation in gender or location type, suggesting that these variables may have limited discriminative power for segmentation.\n",
    "Regarding education, the majority of loyalty members hold a Bachelor’s degree, followed by those with College-level education.\n",
    "In terms of marital status, most customers are married, which may indicate a stable and mature demographic segment.\n",
    "The loyalty status distribution reveals that most clients belong to the Star tier, followed by Nova and Aurora, highlighting a concentration in mid-level membership.\n",
    "Finally, the enrollment type indicates that the majority of customers joined through the Standard enrollment process, which could suggest limited participation in promotional or referral programs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c479f2d6",
   "metadata": {},
   "source": [
    "#### 4.1.2 Distribution of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "id": "6deb1c44",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x=customer[\"EnrollmentDateOpening\"].dt.year, data=customer)\n",
    "plt.title(\"Enrollment per year\")\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x=customer[\"EnrollmentDateOpening\"].dt.month, data=customer)\n",
    "plt.title(\"Enrollment per month\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()\n",
    "customer.head(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "01ab1542",
   "metadata": {},
   "source": [
    "The analysis of enrollment trends shows a stable customer acquisition rate between 2016 and 2020, followed by a significant surge in 2021, which represents the highest volume of new enrollments within the dataset. This latest growth suggests successful recent marketing or promotional efforts and indicates a healthy expansion of the customer base. 2021 Promotion"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3f14e52",
   "metadata": {},
   "source": [
    "monthly_enrollments = customer.groupby(customer[\"EnrollmentDateOpening\"].dt.to_period(\"M\")).size().sort_index()\n",
    "# converter índice PeriodIndex para timestamp para plot ficar com labels de datas\n",
    "monthly_enrollments.index = monthly_enrollments.index.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "monthly_enrollments.plot(kind='line', marker='o', color='teal')\n",
    "plt.title(\"Monthly evolution of enrollment\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"New clients\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f4592a3",
   "metadata": {},
   "source": [
    "\n",
    "valid_dates = customer[\"CancellationDate\"].dt.year != 1904\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=customer.loc[valid_dates, \"CancellationDate\"].dt.year.astype(int).sort_values())\n",
    "plt.title(\"Cancellations per year\")\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=customer.loc[valid_dates, \"CancellationDate\"].dt.month.astype(int))\n",
    "plt.title(\"Cancellations per month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1198dfb7",
   "metadata": {},
   "source": [
    "monthly_enroll = customer.groupby(customer[\"EnrollmentDateOpening\"].dt.to_period(\"M\")).size()\n",
    "monthly_cancel = customer.loc[valid_dates].groupby(customer.loc[valid_dates, \"CancellationDate\"].dt.to_period(\"M\")).size()\n",
    "\n",
    "# Criar range completo de meses para alinhar as séries\n",
    "all_months = pd.period_range(\n",
    "    start=min(monthly_enroll.index.min(), monthly_cancel.index.min()),\n",
    "    end=max(monthly_enroll.index.max(), monthly_cancel.index.max()),\n",
    "    freq=\"M\"\n",
    ")\n",
    "\n",
    "# Reindexar para garantir continuidade\n",
    "monthly_enroll = monthly_enroll.reindex(all_months, fill_value=0)\n",
    "monthly_cancel = monthly_cancel.reindex(all_months, fill_value=0)\n",
    "\n",
    "# Converter PeriodIndex em datetime (para eixo legível)\n",
    "monthly_enroll.index = monthly_enroll.index.to_timestamp()\n",
    "monthly_cancel.index = monthly_cancel.index.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(monthly_enroll.index, monthly_enroll, marker='o', label=\"Enrollment\", color='teal')\n",
    "plt.plot(monthly_cancel.index, monthly_cancel, marker='o', label=\"Cancelation\", color='salmon')\n",
    "plt.title(\"Enrollments Vs Cancellations\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Clients\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ef35df7",
   "metadata": {},
   "source": [
    "numeric_customer = [\"Income\", \"Customer Lifetime Value\"]\n",
    "customer[numeric_customer].hist(bins=30 ,figsize=(10,4))\n",
    "plt.suptitle(\"Numeric Feature Distributions\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d7287e3b",
   "metadata": {},
   "source": [
    "The distributions of Income and Customer Lifetime Value are highly right-skewed, with the vast majority of customers concentrated at low values. The presence of a long tail suggests potential high-value customers, but these instances should be investigated to determine if they represent a genuine business segment (e.g., corporate clients) or data outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "796b7837",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for i, cat_col in enumerate(categorical_customer, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    sns.boxplot(x=cat_col, y=\"Customer Lifetime Value\", data=customer)\n",
    "    plt.title(f\"CLV by {cat_col}\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, cat_col in enumerate(categorical_customer, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    sns.boxplot(x=cat_col, y=\"Income\", data=customer)\n",
    "    plt.title(f\"Income by {cat_col}\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7479de35",
   "metadata": {},
   "source": [
    "def find_group_outliers(df, group_col, value_col, k=1.5):\n",
    "    outlier_idx = []\n",
    "    for name, g in df.groupby(group_col):\n",
    "        q1 = g[value_col].quantile(0.25)\n",
    "        q3 = g[value_col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - k * iqr\n",
    "        upper = q3 + k * iqr\n",
    "        mask = (g[value_col] < lower) | (g[value_col] > upper)\n",
    "        outlier_idx.extend(g[mask].index.tolist())\n",
    "    return df.loc[outlier_idx]\n",
    "\n",
    "def outliers_for_all(df, cat_cols, value_cols=(\"Customer Lifetime Value\", \"Income\"), k=1.5):\n",
    "    results = {}\n",
    "    for val in value_cols:\n",
    "        print(f\"\\n--- {val} ---\")\n",
    "        # compute outliers per categorical column\n",
    "        for col in cat_cols:\n",
    "            out = find_group_outliers(df, col, val, k=k)\n",
    "            results[(col, val)] = out\n",
    "            print(f\"{col}: {len(out)} outliers\")\n",
    "    return results\n",
    "\n",
    "outliers_dict = outliers_for_all(customer, categorical_customer)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "67806a49",
   "metadata": {},
   "source": [
    "**Income Distribution by Loyalty Status**\n",
    "\n",
    "The median Income is similar but slightly lower for the Star loyalty group compared to Aurora and Nova. However, the overall distribution and range of Income across all three groups are highly consistent, with the Interquartile Ranges (IQR) and whiskers spanning similar values (from approximately $0 to $100,000). This suggests that Loyalty Status is not a strong differentiator of customer income levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444d333",
   "metadata": {},
   "source": [
    "**Customer liftime value by Loyalty Status**\n",
    "\n",
    "The plot shows that high-CLV customers (outliers) are not segregated within a single, premium loyalty status; they are present across all three loyalty statuses (Star, Aurora, and Nova). While the Aurora tier shows a slightly higher median CLV, the overall pattern suggests that Loyalty Status is a poor predictor of a customer's lifetime value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff84d70",
   "metadata": {},
   "source": [
    "**Income Distribution by Education Level**\n",
    "The analysis reveals that a Bachelor's degree is the dominant factor determining high customer income, with this group showing a significantly higher median and broader Interquartile Range (IQR) than all others. In contrast, Master's, High School, and Doctor levels show consistently low and similar median incomes. Crucially, the College category displays a median income of zero, pointing to a severe data quality issue (missing or improperly coded income values) that must be addressed prior to any predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "id": "7a84a0cc",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Income', y='Customer Lifetime Value', data=customer)\n",
    "plt.title('Income vs Customer Lifetime Value')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1637f558",
   "metadata": {},
   "source": [
    "The scatter plot confirms that there is no strong linear correlation between Income and Customer Lifetime Value (CLV). High-CLV customers (the upper outliers) are observed across the entire income spectrum, demonstrating that a customer's purchasing power is not the primary driver of their long-term value. This suggests that predictive models should prioritize behavioral features over income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff361ef8e6e824c1",
   "metadata": {},
   "source": [
    "### 4.2 Flights Database"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b8f56d41f500b64",
   "metadata": {},
   "source": [
    "flight.describe().T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "84217790d254f4",
   "metadata": {},
   "source": [
    "#### 4.2.1 Distribution of Numerical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c2c2148",
   "metadata": {},
   "source": [
    "numeric_flights = [\"NumFlights\", \"NumFlightsWithCompanions\", \"DistanceKM\", \"PointsAccumulated\", \"PointsRedeemed\", \"DollarCostPointsRedeemed\"]\n",
    "\n",
    "# Histograms\n",
    "flight[numeric_flights].hist(bins=30, figsize=(20, 10))\n",
    "plt.suptitle(\"Numeric Feature Distributions\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identificar outliers usando IQR\n",
    "Q1 = flight[numeric_flights].quantile(0.25)\n",
    "Q3 = flight[numeric_flights].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = ((flight[numeric_flights] < (Q1 - 1.5 * IQR)) | (flight[numeric_flights] > (Q3 + 1.5 * IQR))).sum()\n",
    "print(\"Número de outliers por variável:\")\n",
    "print(outliers)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e1edb14124fe8f97",
   "metadata": {},
   "source": [
    "### 4.3 Multivariate analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd0714e96192b2aa",
   "metadata": {},
   "source": [
    "flight.groupby([\"Year\", \"Month\"])[\"NumFlights\"].sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7777a7a7ebdf532",
   "metadata": {},
   "source": [
    "# Choosing the style \n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Create the graph\n",
    "ax = sns.lineplot(\n",
    "        data=flight,\n",
    "        x=\"Month\",\n",
    "        y=\"NumFlights\",\n",
    "        hue=\"Year\",\n",
    "        palette=\"viridis\",  # Color scheme\n",
    "        linewidth=2.5,\n",
    "        marker='o',         # Add markers\n",
    "        markersize=8     \n",
    "    )\n",
    "\n",
    "plt.title(\"Monthly variation in flights per year\",\n",
    "            fontsize=16,\n",
    "            fontweight='bold',\n",
    "            pad=20)\n",
    "plt.ylabel('Number of Flights (10^3)', fontsize=12, labelpad=10)\n",
    "\n",
    "plt.legend(\n",
    "        title='Year',\n",
    "        title_fontsize=12,\n",
    "        fontsize=10,\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        framealpha=0.9,\n",
    "        shadow=True,\n",
    "        borderpad=1\n",
    ")\n",
    "\n",
    "plt.xticks(range(1, 13),\n",
    "           ['Jan', 'Fev', 'Mar', 'April', 'May', 'Jun',\n",
    "            'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "           rotation=45)\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "sns.despine(trim=True, left=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7491b87b",
   "metadata": {},
   "source": [
    "#sns.pairplot(data=flight, vars= numeric_flights)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "# meti # para nao demorar a correr"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af18ae08",
   "metadata": {},
   "source": [
    "During the exploration, several features were found to have strong linear relationships. These are not coincidental correlations but rather indicators of specific business rules used by the airline.\n",
    "\n",
    "A strong positive correlation was observed between DistanceKM and PointsAccumulated. This is expected, as it reflects the loyalty program's core mechanic: customers earn points based on the distance they fly.\n",
    "\n",
    "However, the analysis revealed a more precise calculation. The data shows that the number of points awarded is based on a fixed ratio. For example, flights of 2,388 km and 2,380 km both yield 238 points. This strongly suggests that the business rule is PointsAccumulated = floor(DistanceKM / 10).\n",
    "\n",
    "This means that points are awarded for every full 10 kilometers flown, and any remaining unit-level distance is truncated. Understanding this specific rule is key, as it explains the exact, predictable nature of how points are earned.\n",
    "\n",
    "Similarly, the strong correlation between PointsRedeemed and DollarCostPointsRedeemed points to a derived relationship, not a behavioral one.\n",
    "\n",
    "The DollarCostPointsRedeemed is likely an internal accounting metric. It is almost certainly calculated by multiplying the PointsRedeemed by a fixed monetary rate (a \"cost-per-point\") that the airline uses to track the financial liability of its loyalty program. This makes one variable a direct linear function of the other, explaining the perfect or near-perfect correlation.\n",
    "\n",
    "The heatmap below comprove the things that we observed"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e91f26d",
   "metadata": {},
   "source": [
    "\n",
    "correlation_matrix = flight[numeric_flights].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True,           \n",
    "            cmap='coolwarm',     \n",
    "            vmin=-1, vmax=1,      \n",
    "            center=0,             \n",
    "            square=True,          \n",
    "            fmt='.2f',            \n",
    "            cbar_kws={'shrink': 0.8})  \n",
    "\n",
    "plt.title(\"Correlation Heatmap - flight\")\n",
    "plt.show()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d859379",
   "metadata": {},
   "source": [
    "numeric_cols = [\n",
    "    'NumFlights',\n",
    "    'DistanceKM',\n",
    "    'PointsAccumulated',\n",
    "    'PointsRedeemed',\n",
    "    'DollarCostPointsRedeemed',\n",
    "    'Customer Lifetime Value',\n",
    "    'Income'\n",
    "]\n",
    "\n",
    "merged = pd.merge(customer, flight, on='Loyalty#', how='inner')\n",
    "agg = merged.groupby('Loyalty#', as_index=False).agg({\n",
    "    'NumFlights': 'sum',\n",
    "    'DistanceKM': 'sum',\n",
    "    'PointsAccumulated': 'sum',\n",
    "    'PointsRedeemed': 'sum',\n",
    "    'DollarCostPointsRedeemed': 'sum',\n",
    "    'Customer Lifetime Value': 'mean',\n",
    "    'Income': 'first',\n",
    "    'LoyaltyStatus': 'first',\n",
    "    'Gender': 'first',\n",
    "    'Education': 'first',\n",
    "})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b8aabb3",
   "metadata": {},
   "source": [
    "#n_rows = len(categorical_customer)\n",
    "#n_cols = len(numeric_flights)\n",
    "\n",
    "#fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 4*n_rows))\n",
    "\n",
    "#for i, cat in enumerate(categorical_customer):\n",
    "    #for j, num in enumerate(numeric_flights):\n",
    "        #ax = axes[i, j]\n",
    "        #sns.boxplot(x=cat, y=num, data=merged, ax=ax)\n",
    "        #ax.set_title(f'{num} by {cat}')\n",
    "        #ax.set_xlabel('')\n",
    "        #ax.set_ylabel('')\n",
    "        #ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# meti # para nao demorar a correr"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c6c0dd7",
   "metadata": {},
   "source": [
    "#sns.pairplot(merged[numeric_cols], diag_kind='kde', plot_kws={'alpha':0.6})\n",
    "#plt.suptitle('Pairplot – Customer & Flight Numerical Variables', y=1.02)\n",
    "#plt.show()\n",
    "\n",
    "# so coloquei # para nao demorar a correr\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8466517",
   "metadata": {},
   "source": [
    "## 5. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de851a721fbc085",
   "metadata": {},
   "source": [
    "### 5.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d1f7c",
   "metadata": {},
   "source": [
    "This section aggregates flight-related data for each customer based on their unique Loyalty# identifier.\n",
    "A reusable function (cumulative_customer) is defined to compute the total sum of a selected column (e.g., number of flights, distance traveled, points accumulated, and points redeemed) per customer.\n",
    "The resulting aggregated datasets are then merged into the main customer DataFrame to enrich it with cumulative statistics for each individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb689667efe95",
   "metadata": {},
   "source": [
    "#### 5.1.1 Cumulative Customer Totals\n",
    "\n",
    "Total values of flights, distance, points redeemed/accumulated, and flights with companions for each customer, capturing overall activity."
   ]
  },
  {
   "cell_type": "code",
   "id": "ff1bc96a4fac275a",
   "metadata": {},
   "source": [
    "total_flights = cumulative_customer(\"NumFlights\",flight)\n",
    "total_DistanceKM = cumulative_customer(\"DistanceKM\",flight)\n",
    "total_PointsRedeemed = cumulative_customer(\"PointsRedeemed\",flight)\n",
    "total_PointsAccumulated = cumulative_customer(\"PointsAccumulated\",flight)\n",
    "total_NumFlightsWithCompanions = cumulative_customer(\"NumFlightsWithCompanions\",flight)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2dd7cd14117fe273",
   "metadata": {},
   "source": [
    "features = {\n",
    "    \"Total NumFlights\": total_flights['NumFlights'],\n",
    "    \"Total Distance KM\": total_DistanceKM['DistanceKM'],\n",
    "    \"Total Points Redeemed\": total_PointsRedeemed['PointsRedeemed'],\n",
    "    \"Total Points Accumulated\": total_PointsAccumulated['PointsAccumulated'],\n",
    "    \"Total Flights With Companions\": total_NumFlightsWithCompanions['NumFlightsWithCompanions']\n",
    "}\n",
    "\n",
    "for name, feat in features.items():\n",
    "    analyze_feature(feat, feature_name=name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "553b4f5959ed8044",
   "metadata": {},
   "source": [
    "#### 5.1.2 Seasonality Features\n",
    "\n",
    "Features that capture seasonal patterns in customer flight behavior, showing periods of higher or lower activity throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "id": "a8b6e0c5",
   "metadata": {},
   "source": [
    "seasonality_data = calculate_seasonality(flight)\n",
    "\n",
    "\n",
    "for col in ['Summer_Ratio', 'Fall_Ratio', 'Spring_Ratio', 'Winter_Ratio', 'Seasonality_Index']:\n",
    "    analyze_feature(seasonality_data[col], feature_name=col)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3f946a1b5a023ecc",
   "metadata": {},
   "source": [
    "#### 5.1.3 Trend Feature\n",
    "\n",
    "Feature representing the trend of the number of flights per customer over time, indicating whether activity is increasing or decreasing."
   ]
  },
  {
   "cell_type": "code",
   "id": "6a9a25005e7afcdd",
   "metadata": {},
   "source": [
    "trend_data = calculate_trend(flight)\n",
    "\n",
    "analyze_feature(trend_data['Flight_Trend_Slope'], feature_name='Flight Trend Slope')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5276aa26b95ed0a2",
   "metadata": {},
   "source": [
    "#### 5.1.4 Integrating New Features\n",
    "\n",
    "Merge all newly created features (cumulative totals, seasonality, and trend) into the main customer dataframe."
   ]
  },
  {
   "cell_type": "code",
   "id": "336922c8ec8d758e",
   "metadata": {},
   "source": [
    "new_columns = [\n",
    "    total_flights,\n",
    "    total_DistanceKM,\n",
    "    total_PointsRedeemed,\n",
    "    total_PointsAccumulated,\n",
    "    total_NumFlightsWithCompanions,\n",
    "    seasonality_data,\n",
    "    trend_data\n",
    "]\n",
    "\n",
    "\n",
    "for data in new_columns:\n",
    "    customer = customer.merge(data, on=\"Loyalty#\", how=\"left\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cb17322d8b04e080",
   "metadata": {},
   "source": [
    "#### 5.1.5 Derived Ratios\n",
    "\n",
    "Features derived from existing metrics, such as the proportion of flights with companions and average distance per flight, providing more granular insights into customer behavior."
   ]
  },
  {
   "cell_type": "code",
   "id": "640992f2d0850356",
   "metadata": {},
   "source": [
    "customer = customer.fillna(0)\n",
    "customer['Companion_Ratio'] = customer['NumFlightsWithCompanions'] / customer['NumFlights']\n",
    "customer['Avg_Distance_Flight'] = customer['DistanceKM'] / customer['NumFlights']\n",
    "\n",
    "\n",
    "customer = customer.replace([np.inf, -np.inf], 0)\n",
    "customer[['Companion_Ratio', 'Avg_Distance_Flight']] = customer[['Companion_Ratio', 'Avg_Distance_Flight']].fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ad384f56cce1647",
   "metadata": {},
   "source": [
    "analyze_feature(customer['Companion_Ratio'], feature_name='Companion Ratio')\n",
    "analyze_feature(customer['Avg_Distance_Flight'], feature_name='Avg Distance Flight')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8a7bc0e1146d62c",
   "metadata": {},
   "source": [
    "#### 5.1.6 Temporal Customer Features\n",
    "\n",
    "- **Recency**: Months since the last flight.\n",
    "- **Tenure**: Days since the customer account was client of the company."
   ]
  },
  {
   "cell_type": "code",
   "id": "d4717e500d465355",
   "metadata": {},
   "source": [
    "last_flight = (\n",
    "    flight[flight['NumFlights'] > 0]\n",
    "    .groupby('Loyalty#')['YearMonthDate']\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={'YearMonthDate': 'last_flight_date'})\n",
    ")\n",
    "reference_date = flight['YearMonthDate'].max()\n",
    "\n",
    "last_flight['recency_months'] = (\n",
    "        (reference_date.year - last_flight['last_flight_date'].dt.year) * 12 +\n",
    "        (reference_date.month - last_flight['last_flight_date'].dt.month)\n",
    ")\n",
    "customer = customer.merge(last_flight[['Loyalty#', 'recency_months']], on='Loyalty#', how='left')\n",
    "customer.replace({\"recency_months\": {np.nan: -1}}, inplace=True)\n",
    "customer['recency_months'] = customer['recency_months'].astype(int)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2c900a5",
   "metadata": {},
   "source": [
    "customer[\"Tenure\"] = (pd.Timestamp.today() - customer[\"EnrollmentDateOpening\"]).dt.days\n",
    "customer.sort_values(by='Tenure', ascending=True, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "114b7af32e9821a7",
   "metadata": {},
   "source": [
    "analyze_feature(customer['recency_months'], feature_name='Recency Months')\n",
    "analyze_feature(customer['Tenure'], feature_name='Tenure')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "94ca4c45336a85d1",
   "metadata": {},
   "source": [
    "#### 5.1.7 Engagement/Loyalty Metrics\n",
    "\n",
    "Proportion of points redeemed vs accumulated, indicating customer engagement with the loyalty program:\n",
    "\n",
    "- High Value (Near 1): Client that use points frequently, can indicate that the client engage and likes rewards\n",
    "- Baixo valor (Near 0): Client that don't accumulate, can show some disinterest, or lack of importance/attention with the rewards.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d59449ce3e13c7cc",
   "metadata": {},
   "source": [
    "customer[\"PointsUtilizationRate\"] = customer[\"PointsRedeemed\"] / (customer[\"PointsAccumulated\"] + 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0818b011946752e",
   "metadata": {},
   "source": [
    "analyze_feature(customer['PointsUtilizationRate'], feature_name='Points Utilization Rate')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b870e8b99d9abcfd",
   "metadata": {},
   "source": [
    "#### 5.1.8 New Customer Lifetime Value (CLV)\n",
    "\n",
    "New normalized metric combining number of flights, income, and tenure to estimate the long-term value of each customer."
   ]
  },
  {
   "cell_type": "code",
   "id": "46de5c80",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "cols_to_combine = ['NumFlights', 'Income', 'Tenure']\n",
    "\n",
    "df_temp_calc = pd.DataFrame(scaler.fit_transform(customer[cols_to_combine]), \n",
    "                            columns=cols_to_combine, \n",
    "                            index=customer.index)\n",
    "\n",
    "# nova fórmula de CLV com pesos ajustados\n",
    "customer['CLV'] = (\n",
    "    (df_temp_calc['NumFlights'] * 0.50) + \n",
    "    (df_temp_calc['Income'] * 0.30) + \n",
    "    (df_temp_calc['Tenure'] * 0.20)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13ec8549bed78391",
   "metadata": {},
   "source": [
    "analyze_feature(customer['CLV'], feature_name='CLV')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d76c62fc7a0067cc",
   "metadata": {},
   "source": [
    "#### (Bonus) Map Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463fdefa23769b",
   "metadata": {},
   "source": [
    "NOTE: \n",
    " The map is interactive. Hover over the data points to view detailed information"
   ]
  },
  {
   "cell_type": "code",
   "id": "f4af0a830a4ec2cd",
   "metadata": {},
   "source": [
    "# Group by Province/State and count the number of customers\n",
    "customermap = customer.groupby(\"Province or State\").agg({\n",
    "    \"Loyalty#\": \"count\",  # Count number of customers\n",
    "    \"Latitude\": \"first\",\n",
    "    \"Longitude\": \"first\",\n",
    "    \"LoyaltyStatus\": lambda x: x.mode()[0],\n",
    "    \"NumFlights\": \"mean\",\n",
    "    \"DistanceKM\": \"mean\",\n",
    "}).reset_index().rename(columns={\"Loyalty#\": \"NumCustomers\"})\n",
    "\n",
    "# Create the map\n",
    "fig = px.scatter_mapbox(\n",
    "    customermap,\n",
    "    lat=\"Latitude\",\n",
    "    lon=\"Longitude\",\n",
    "    size=\"NumCustomers\",\n",
    "    color=\"NumCustomers\",\n",
    "    hover_name=\"Province or State\",\n",
    "    hover_data={\"NumCustomers\": True, \"Latitude\": False, \"Longitude\": False, \"NumFlights\": True, \"DistanceKM\" : True, \"LoyaltyStatus\": True},\n",
    "    zoom=3,\n",
    "    height=700,\n",
    "    title=\"Number of Customers by Canadian Province/State\",\n",
    "    color_continuous_scale=px.colors.sequential.Viridis\n",
    ")\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    margin={\"r\": 0, \"t\": 50, \"l\": 0, \"b\": 0},\n",
    "    coloraxis_colorbar=dict(\n",
    "        title=\"Number of Customers\",\n",
    "        thicknessmode=\"pixels\",\n",
    "        thickness=20,\n",
    "        lenmode=\"pixels\",\n",
    "        len=300,\n",
    "        yanchor=\"top\",\n",
    "        y=1,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "82e5f214",
   "metadata": {},
   "source": [
    "### 5.2 Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "id": "eabeb2b70982a784",
   "metadata": {},
   "source": [
    "customer.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "258084ca",
   "metadata": {},
   "source": [
    "metric_features = [\n",
    "    \"Income\",\n",
    "    \"CLV\",\n",
    "    \"NumFlights\",\n",
    "    \"DistanceKM\",\n",
    "    \"PointsRedeemed\",\n",
    "    \"PointsAccumulated\",\n",
    "    \"NumFlightsWithCompanions\",\n",
    "\n",
    "    \"Fall_Ratio\",\n",
    "    \"Spring_Ratio\",\n",
    "    \"Summer_Ratio\",\n",
    "    \"Winter_Ratio\",\n",
    "    \"Seasonality_Index\",\n",
    "\n",
    "    \"Flight_Trend_Slope\",\n",
    "    \"Companion_Ratio\",\n",
    "    \"Avg_Distance_Flight\",\n",
    "\n",
    "    \"recency_months\",\n",
    "    \"Tenure\",\n",
    "    \"PointsUtilizationRate\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'Gender',\n",
    "    'Education',\n",
    "    'Marital Status',\n",
    "    'EnrollmentType',\n",
    "    'Province or State',\n",
    "    'City'\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4272df3",
   "metadata": {},
   "source": [
    "customer_oh = pd.get_dummies(customer[categorical_features], prefix='oh', drop_first=True, dtype=int)\n",
    "customer = pd.concat([customer, customer_oh], axis=1)\n",
    "non_metric_features = customer.columns[customer.columns.str.startswith('oh_')].tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e37c71b5",
   "metadata": {},
   "source": [
    "features_to_use = metric_features + non_metric_features\n",
    "\n",
    "unused_features = [col for col in customer.columns if col not in features_to_use]\n",
    "\n",
    "print(f\"Features Métricas ({len(metric_features)}): {metric_features}\")\n",
    "print(f\"Features One-Hot ({len(non_metric_features)}): {non_metric_features}\")\n",
    "print(f\"Features Unused/Descartadas ({len(unused_features)}): {unused_features}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "30519105",
   "metadata": {},
   "source": [
    "customer = customer[metric_features + non_metric_features].copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1de5672a",
   "metadata": {},
   "source": [
    "### 5.3 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "id": "04b86921",
   "metadata": {},
   "source": [
    "columns_to_drop = [\n",
    "    # --- Identificadores & PII ---\n",
    "    'Loyalty#', 'First Name', 'Last Name', 'Customer Name',\n",
    "    'Country', 'Postal code', 'Latitude', 'Longitude',\n",
    "\n",
    "    # --- Originais categóricas (já codificadas) ---\n",
    "    'Gender',\n",
    "    'Education',\n",
    "    'Marital Status',\n",
    "    'EnrollmentType',\n",
    "    'Province or State',\n",
    "    'City',\n",
    "    'Location Code',\n",
    "    'LoyaltyStatus',\n",
    "\n",
    "    # --- Datas ---\n",
    "    'EnrollmentDateOpening',\n",
    "    'CancellationDate',\n",
    "\n",
    "    # --- Redundâncias ---\n",
    "    'Customer Lifetime Value',\n",
    "    'DistanceKM',\n",
    "    'PointsRedeemed',\n",
    "    'PointsAccumulated',\n",
    "    'NumFlightsWithCompanions'\n",
    "]\n",
    "\n",
    "customer = customer.drop(columns=columns_to_drop, errors='ignore')\n",
    "customer.head(3)\n",
    "\n",
    "fs_metric_features = [f for f in metric_features if f in customer.columns]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef1c1a55",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "corr = customer[fs_metric_features].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Heatmap – Customer & Flight Variables')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f2d43798",
   "metadata": {},
   "source": [
    "### 5.4 Feature Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abcda6b",
   "metadata": {},
   "source": [
    "#### 5.4.1 MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "id": "466b4e34",
   "metadata": {},
   "source": [
    "df_minmax = customer.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4440daa1",
   "metadata": {},
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaled_feat = mm_scaler.fit_transform(df_minmax[fs_metric_features])\n",
    "\n",
    "df_minmax[fs_metric_features] = mm_scaled_feat\n",
    "df_minmax[fs_metric_features].describe().T.round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8bd92a4",
   "metadata": {},
   "source": [
    "MinMaxScaler compresses all data points into a fixed range between 0 and 1, where the lowest value becomes 0 and the highest becomes 1, ensuring that no single variable dominates the model simply because it has larger raw numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf61566",
   "metadata": {},
   "source": [
    "#### 5.4.2 StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8f373e7",
   "metadata": {},
   "source": [
    "df_standard = customer.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1088dcef",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "ss_scaled_feat = scaler.fit_transform(customer[fs_metric_features])\n",
    "\n",
    "df_standard[fs_metric_features] = ss_scaled_feat\n",
    "df_standard[fs_metric_features].describe().T.round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c772884f",
   "metadata": {},
   "source": [
    "StandardScaler transforms the data so that the mean is 0 and the standard deviation is 1. It tells us how many standard deviations a data point is above or below the average, without imposing fixed maximum or minimum limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d077ae7",
   "metadata": {},
   "source": [
    "#### 5.4.3 Comparing different scalers vs original data"
   ]
  },
  {
   "cell_type": "code",
   "id": "10f997af",
   "metadata": {},
   "source": [
    "\n",
    "sns.set_style('whitegrid')\n",
    "# Aumentar o figsize para que 6 boxplots fiquem legíveis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 5), tight_layout=True, sharey='row')\n",
    "\n",
    "bp_feat_l = 'Income'\n",
    "\n",
    "sns.boxplot(customer, x=bp_feat_l, ax=axes[0][0], width=.4)\n",
    "axes[0][0].set_title('Original')\n",
    "axes[0][0].set_ylabel(bp_feat_l)\n",
    "\n",
    "sns.boxplot(df_minmax, x=bp_feat_l, ax=axes[0][1], width=.4)\n",
    "axes[0][1].set_title('MinMaxScaler()')\n",
    "\n",
    "sns.boxplot(df_standard, x=bp_feat_l, ax=axes[0][2], width=.4)\n",
    "axes[0][2].set_title('StandardScaler()')\n",
    "\n",
    "\n",
    "\n",
    "bp_feat_r = 'NumFlights'\n",
    "\n",
    "sns.boxplot(customer, x=bp_feat_r, ax=axes[1][0], width=.4)\n",
    "axes[1][0].set_ylabel(bp_feat_r)\n",
    "\n",
    "sns.boxplot(df_minmax, x=bp_feat_r, ax=axes[1][1], width=.4)\n",
    "\n",
    "sns.boxplot(df_standard, x=bp_feat_r, ax=axes[1][2], width=.4)\n",
    "\n",
    "\n",
    "axes[1][0].set_xlabel(None)\n",
    "axes[1][1].set_xlabel(None)\n",
    "axes[1][2].set_xlabel(None)\n",
    "\n",
    "fig.suptitle('Boxplots: \"{}\" and \"{}\"'.format(bp_feat_l, bp_feat_r))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "48a0a4db",
   "metadata": {},
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(8,5), tight_layout=True,)\n",
    "\n",
    "sns.boxplot(customer, x=bp_feat_l, ax=axes[2], width=.4)\n",
    "sns.boxplot(df_minmax, x=bp_feat_l, ax=axes[1], width=.4)\n",
    "sns.boxplot(df_standard, x=bp_feat_l, ax=axes[0], width=.4)\n",
    "\n",
    "axes[0].set_title(\"StandardScaler()\")\n",
    "axes[0].set_xlabel(None)\n",
    "axes[1].set_title(\"MinMaxScaler()\")\n",
    "axes[1].set_xlabel(None)\n",
    "axes[2].set_title(\"original\")\n",
    "axes[2].set_xlabel(None)\n",
    "\n",
    "plt.suptitle('Boxplots: \"{}\"'.format(bp_feat_l))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a70bd31d",
   "metadata": {},
   "source": [
    "As we can see through the boxplots, MinMaxScaler forces the data into the 0-1 interval destroying the subtle differences in variance among average customers. This compression leads to clustering results that are less discriminatory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72934c10",
   "metadata": {},
   "source": [
    "StandardScaler preserves the relative distances between data points. This makes it ideal for the distance-based algorithms that we will use later, as it ensures that distances are calculated fairly and robustly across all features."
   ]
  },
  {
   "cell_type": "code",
   "id": "52d689ff",
   "metadata": {},
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create subplots with 3 rows, 1 column:\n",
    "fig, axes = plt.subplots(3,1, \n",
    "                         figsize=(5,5), tight_layout=True)\n",
    "\n",
    "# Which feature do you want to visualize?\n",
    "hp_feat = 'Income'\n",
    "\n",
    "# common function args for histplot\n",
    "hp_args = dict(x=hp_feat, bins=15)\n",
    "\n",
    "\n",
    "sns.histplot(customer, ax=axes[0], **hp_args)\n",
    "axes[0].set_title('{}: Original'.format(hp_feat))\n",
    "axes[0].set_xlabel(None)\n",
    "\n",
    "sns.histplot(df_minmax, ax=axes[1], **hp_args)\n",
    "axes[1].set_title('{}: MinMaxScaler()'.format(hp_feat))\n",
    "axes[1].set_xlabel(None)\n",
    "\n",
    "sns.histplot(df_standard, ax=axes[2], **hp_args)\n",
    "axes[2].set_title('{}: StandardScaler()'.format(hp_feat))\n",
    "axes[2].set_xlabel(None)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "sns.set()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ae7777e",
   "metadata": {},
   "source": [
    "We decided to keep the StandardScaler because it best preserved relative distances across features and provided the most suitable scaling for our clustering objectives."
   ]
  },
  {
   "cell_type": "code",
   "id": "1dbef29f",
   "metadata": {},
   "source": [
    "customer = df_standard.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a4d77f2",
   "metadata": {},
   "source": [
    "sns.set()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ccf4ae70",
   "metadata": {},
   "source": [
    "### 5.5 Outliers removal (DBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d969b3",
   "metadata": {},
   "source": [
    "We create a clean dataset using DBSCAN for K-Means training, ensuring that centroids are not distorted by extreme values. However, these outliers are saved in df_outliers for separate analysis, as they can also represent valuable customers."
   ]
  },
  {
   "cell_type": "code",
   "id": "e42c1cca",
   "metadata": {},
   "source": [
    "len(fs_metric_features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57c07f48",
   "metadata": {},
   "source": [
    "neigh = NearestNeighbors(n_neighbors=28) #2* nr de features\n",
    "neigh.fit(customer[fs_metric_features])\n",
    "distances, _ = neigh.kneighbors(customer[fs_metric_features])\n",
    "\n",
    "# Ordenar e plotar\n",
    "distances = np.sort(distances[:, -1], axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances)\n",
    "plt.title('K-Distance Graph for eps Selection', fontsize=14)\n",
    "plt.xlabel('customers')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=1.8, color='r', linestyle='--', label='Potential eps (elbow)')\n",
    "plt.ylim(0,4)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "427a3acd",
   "metadata": {},
   "source": [
    "all_customers = customer.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8cf62e8",
   "metadata": {},
   "source": [
    "dbscan = DBSCAN(eps=1.8, min_samples=28, n_jobs=-1) # eps was later found using the K-Distance Graph for eps Selection\n",
    "dbscan_labels = dbscan.fit_predict(customer[fs_metric_features]) # ou features_modelo\n",
    "\n",
    "outlier_count = Counter(dbscan_labels)\n",
    "print(f\"DBSCAN results: {outlier_count}\")\n",
    "print(f\"Outliers detected (-1): {outlier_count[-1]}\")\n",
    "n_core = sum([count for label, count in outlier_count.items() if label != -1])\n",
    "print(f\"Core customers: {n_core}\")\n",
    "\n",
    "customer_out = customer[dbscan_labels == -1].copy()\n",
    "\n",
    "# data frame limpo scaled para o kmeans\n",
    "customer = customer[dbscan_labels != -1].copy()\n",
    "\n",
    "print(f\"\\nWorking with {len(customer):,} core customers, {np.round(customer.shape[0] / all_customers.shape[0], 4)}\")\n",
    "print(f\"Outliers saved for later: {len(customer_out)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "78e64fe25ccc9ec",
   "metadata": {},
   "source": [
    "## 6. Data Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab294f",
   "metadata": {},
   "source": [
    "### 6.1 RFM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb2ee4",
   "metadata": {},
   "source": [
    "alterar M depois do feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced54099",
   "metadata": {},
   "source": [
    "To better understand customer behavior and identify meaningful subgroups, we applied an RFM (recency, frequency, monetary) segmentation model. This method classifies customers based on:\n",
    "- Recency (R): how recently they flew;\n",
    "- Frequency (F): how often they fly;\n",
    "- Monetary (M): how much money they spend.\n",
    "\n",
    "This allows us to highlight high-value customers, at-risk customers, and behavioral patterns relevant for targeted marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ef8cd",
   "metadata": {},
   "source": [
    "atencao: alterar depois monetary (atualmente é CLV, mas temos de mudar)"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d7c6e1f",
   "metadata": {},
   "source": [
    "def create_rfm_quantiles(df, recency, frequency, monetary, rec_ascending=True, freq_ascending=False, mon_ascending=False):\n",
    "    rfm_df = df.copy()\n",
    "\n",
    "    rfm_df[\"R_quintile\"] = pd.qcut(rfm_df[recency].rank(method=\"first\", ascending = rec_ascending),\n",
    "                                   q=5, labels=[1,2,3,4,5]\n",
    "                                   ).astype(int)\n",
    "    rfm_df[\"F_quintile\"] = pd.qcut(rfm_df[frequency].rank(method=\"first\", ascending = freq_ascending),\n",
    "                                   q=5, labels=[1,2,3,4,5]\n",
    "                                   ).astype(int)\n",
    "    rfm_df[\"M_quintile\"] = pd.qcut(rfm_df[monetary].rank(method=\"first\", ascending = mon_ascending),\n",
    "                                   q=5, labels=[1,2,3,4,5]\n",
    "                                   ).astype(int)\n",
    "\n",
    "    rfm_df[\"RFM_score\"] = (rfm_df[\"R_quintile\"].astype(str) + rfm_df[\"F_quintile\"].astype(str) + rfm_df[\"M_quintile\"].astype(str))\n",
    "\n",
    "    return rfm_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b1073f7",
   "metadata": {},
   "source": [
    "customer = create_rfm_quantiles(customer,recency=\"recency_months\",frequency=\"NumFlights\", monetary=\"CLV\", rec_ascending=False, freq_ascending=True, mon_ascending=True)\n",
    "customer.head()\n",
    "customer.iloc[:,17:]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "203b6b9d",
   "metadata": {},
   "source": [
    "Customer segmentation\n",
    "\n",
    "We defined a set of business-driven RFM rules to map each customer into a meaningful segment.  \n",
    "This includes groups such as:\n",
    "\n",
    "| Segment                |  RFM  | Description                                                                 |  Marketing                                              |\n",
    "|------------------------|-------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| **High-value Loyal customers**          | 555               | Recently active, purchase frequently, and spend the most.                   | VIP programs, exclusive rewards, early access to new products.             |\n",
    "| **Loyal Frequent customers**    | X5X               | High purchase frequency, even if not always recent.                         | Personalized offers, loyalty nurturing, regular engagement.                |\n",
    "| **Big spenders**       | XX5               | Highest monetary contribution but not necessarily frequent or recent.       | Promote premium products, upselling opportunities.                         |\n",
    "| **Potential Loyalists**| 515 / 525         | Recent high spenders with still low frequency.                               | Encourage repeat purchases with progressive discounts or subscriptions.    |\n",
    "| **New customers**      | 511 / 512         | Recently acquired but with low spending and low frequency.                  | Welcome campaigns, onboarding flows, recurring purchase incentives.        |\n",
    "| **At Risk customers**  | 155 / 255         | Previously high frequency and/or high spenders, but not recent.             | Re-engagement campaigns, special comeback offers.                          |\n",
    "| **Lost customers**     | 155  | High-value customers who have been inactive for a long time.                | Aggressive recovery campaigns, personalized incentives.                    |\n",
    "| **Lost Cheap customers** | 111             | Long inactive, low frequency, and low spending.                             | Avoid spending resources trying to reacquire.                              |\n",
    "| **Others**             | Mixed             | Customers who don’t fit cleanly into the above priority groups.             | General marketing strategies depending on overall business goals.          |\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3cc323b8",
   "metadata": {},
   "source": [
    "def assign_segment(rfm):\n",
    "        r, f, m = int(rfm[0]), int(rfm[1]), int(rfm[2])\n",
    "\n",
    "        if r == 5 and f == 5 and m == 5:\n",
    "            return \"High-value Loyal customers\"\n",
    "\n",
    "        if f == 5 and not (r == 5 and m == 5):  \n",
    "            return \"Loyal Frequent customers\"\n",
    "\n",
    "        if m == 5 and not (r == 5 and f == 5):\n",
    "            return \"Big spenders\"\n",
    "\n",
    "        if r == 5 and m == 5 and f in [1, 2]:\n",
    "            return \"Potential Loyalists\"\n",
    "\n",
    "        if r == 5 and f == 1 and m in [1,2]:\n",
    "            return \"New customers\"\n",
    "\n",
    "        if (r in [1,2]) and f == 5 and m == 5:\n",
    "            return \"At Risk customers\"\n",
    "\n",
    "        if r == 1 and f == 5 and m == 5:\n",
    "            return \"Lost customers\"\n",
    "\n",
    "        if r == 1 and f == 1 and m == 1:\n",
    "            return \"Lost Cheap customers\"\n",
    "\n",
    "        return \"Others\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1456a36d",
   "metadata": {},
   "source": [
    "customer[\"RFM_segment\"] = customer[\"RFM_score\"].apply(assign_segment)\n",
    "customer[\"RFM_segment\"].value_counts().plot(kind=\"bar\")\n",
    "customer[\"RFM_segment\"].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4846a17f",
   "metadata": {},
   "source": [
    "The final distribution of segments highlights the behavioral diversity within the customer base.  \n",
    "A larger presence of groups such as Loyal customers or Big spenders indicates strong retention and high engagement.  \n",
    "Conversely, the proportion of At Risk or Lost customers reveals potential churn issues that may require dedicated retention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92fac4c7d303c4",
   "metadata": {},
   "source": [
    "## 7. Data Clustering"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a1e847a",
   "metadata": {},
   "source": [
    "fs_metric_features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "96c25875",
   "metadata": {},
   "source": [
    "**Perspectives**"
   ]
  },
  {
   "cell_type": "code",
   "id": "40e11cbee550421b",
   "metadata": {},
   "source": [
    "clustering_perspectives = {\n",
    "    # Value-based segmentation: assesses the economic value and long-term\n",
    "    # relationship of each customer with the company.\n",
    "    \"Value_Segmentation\": [\n",
    "        'CLV',\n",
    "        'Income',\n",
    "        'PointsUtilizationRate',\n",
    "        'Tenure'\n",
    "    ],\n",
    "\n",
    "    # Behavioral segmentation: analyzes how customers travel and how\n",
    "    # their travel behavior evolves over time.\n",
    "    \"Behavioral_Segmentation\": [\n",
    "        'NumFlights',\n",
    "        'Avg_Distance_Flight',\n",
    "        'recency_months',\n",
    "        'Companion_Ratio',\n",
    "        'Flight_Trend_Slope'\n",
    "    ],\n",
    "\n",
    "    # Seasonality segmentation: captures when customers travel during\n",
    "    # the year and their dependency on specific seasons.\n",
    "    \"Seasonality_Segmentation\": [\n",
    "        'Fall_Ratio',\n",
    "        'Spring_Ratio',\n",
    "        'Summer_Ratio',\n",
    "        'Winter_Ratio',\n",
    "        'Seasonality_Index'\n",
    "    ]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6be605e",
   "metadata": {},
   "source": [
    "# Demographic segmentation: quem são os clientes em termos de perfil socioeconómico?\n",
    "Demographic_Segmentation = [\n",
    "        'Province or State',\n",
    "        'City',\n",
    "        'Location Code',\n",
    "        'Gender',\n",
    "        'Education',\n",
    "        'Marital Status'\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9cadbf29",
   "metadata": {},
   "source": [
    "### 7.1 Value segmentation perspective"
   ]
  },
  {
   "cell_type": "code",
   "id": "a5a1c321",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a65c1b702ba6d87",
   "metadata": {},
   "source": [
    "features_val = clustering_perspectives['Value_Segmentation']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be0e0d8f",
   "metadata": {},
   "source": [
    "results_value = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6df1ca3502e214d1",
   "metadata": {},
   "source": [
    "#### 7.1.1 K-means and Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d56da3bdcf57d",
   "metadata": {},
   "source": [
    "To ensure a robust segmentation, we will not rely solely on K-Means.\n",
    "We will compare it against Hierarchical Clustering to validate the number of clusters k and check if the customer groups have irregular shapes. The algorithm that best explains the variance R^2 of the data will be selected for the final profiling."
   ]
  },
  {
   "cell_type": "code",
   "id": "55b0dec0",
   "metadata": {},
   "source": [
    "df_value_kmeans_hc = customer[features_val].copy()\n",
    "df_value_kmeans_hc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee33f4ad",
   "metadata": {},
   "source": [
    "kmeans = KMeans(\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "afd517af",
   "metadata": {},
   "source": [
    "hierarchical = AgglomerativeClustering(\n",
    "    metric='euclidean'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b49131a5",
   "metadata": {},
   "source": [
    "df_value_sample = df_value_kmeans_hc.sample(n=5000, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b04eb565",
   "metadata": {},
   "source": [
    "We used a subset of the data to determine the optimal number of clusters k and the best clustering approach, overcoming the constraints about calculating the distance matrix for the entire population."
   ]
  },
  {
   "cell_type": "code",
   "id": "992e39b9",
   "metadata": {},
   "source": [
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "r2_scores = {}\n",
    "\n",
    "r2_scores['kmeans'] = func.get_r2_scores(df_value_sample, df_value_kmeans_hc.columns.tolist(), kmeans)\n",
    "\n",
    "for linkage in ['complete', 'average', 'single', 'ward']: # 4 different versions of HC\n",
    "    r2_scores[linkage] = func.get_r2_scores(\n",
    "        df_value_sample,                 # data\n",
    "        df_value_kmeans_hc.columns.tolist(),   # features of perspective\n",
    "        # use HClust, changing the linkage at each iteration\n",
    "        hierarchical.set_params(linkage=linkage) \n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "765a89ff",
   "metadata": {},
   "source": [
    "r2_scores_df = pd.DataFrame(r2_scores)\n",
    "r2_scores_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "636c8071",
   "metadata": {},
   "source": [
    "r2_scores_df.plot.line(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Demographic Variables:\\nR² plot for various clustering methods\\n\", fontsize=21)\n",
    "plt.legend(title=\"Cluster methods\", title_fontsize=11)\n",
    "plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "plt.ylabel(\"R² metric\", fontsize=13)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "167841a4",
   "metadata": {},
   "source": [
    "The comparison identifies K-Means as the best algorithm for this dataset, since it achieves the highest R^2 scores across all cluster counts.\n",
    "Analyzing the elbow of the curve reveals that 4 clusters is the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "id": "dffb27a4",
   "metadata": {},
   "source": [
    "df_sample_value_viz = df_value_kmeans_hc.sample(n=3000, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9adc01db",
   "metadata": {},
   "source": [
    "To optimize processing time, we will generate the Silhouette plot using a random subset of 3,000 customers."
   ]
  },
  {
   "cell_type": "code",
   "id": "2aee54ec",
   "metadata": {},
   "source": [
    "func.visualize_silhouette_graf(df_sample_value_viz, range_clusters=range(2, 11))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "52483846",
   "metadata": {},
   "source": [
    "MUDAR Although R^2 plot pointed towards a 4-cluster solution, the analysis of the Silhouette Plot favored k=3.\n",
    "Since the Silhouette score dropped when moving from 3 to 4 clusters (indicating less separation between groups), we chose the Elbow suggestion. We selected k=3 as the final solution to guarantee the most reliable and distinct separation of customer value tiers."
   ]
  },
  {
   "cell_type": "code",
   "id": "ffe593e0",
   "metadata": {},
   "source": [
    "kmeans_value = KMeans(\n",
    "    n_clusters=4,\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3a979f5",
   "metadata": {},
   "source": [
    "\n",
    "value_labels = kmeans_value.fit_predict(df_value_kmeans_hc)\n",
    "value_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9341aeb3",
   "metadata": {},
   "source": [
    "print(pd.Series(value_labels).value_counts().sort_index())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f4a33c87",
   "metadata": {},
   "source": [
    "#### 7.1.2 DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "id": "a91f7a0c",
   "metadata": {},
   "source": [
    "k_val = plot_k_distance(customer, features_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d85956ad",
   "metadata": {},
   "source": [
    "dbscan_results = {}\n",
    "\n",
    "labels_val, n_clus_val, dist_val = get_dbscan(\n",
    "    customer, \n",
    "    features_val, \n",
    "    eps=0.35,\n",
    "    min_samples=7\n",
    ")\n",
    "\n",
    "dbscan_results['Value'] = {'Clusters': n_clus_val, 'Distribution': dist_val}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we can see a good example of a bad clustering solution, where DBSCAN creates a large number of small clusters and a few large clusters. Its does not provide a clear separation between clusters and it is not a good solution for this dataset.",
   "id": "cb3eaf9d9904528f"
  },
  {
   "cell_type": "markdown",
   "id": "c611a167",
   "metadata": {},
   "source": [
    "#### 7.1.3 HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f4dfc1c",
   "metadata": {},
   "source": [
    "labels_hdb_val, n_hdb_val, dist_hdb_val = func.get_hdbscan(\n",
    "    customer, \n",
    "    features_val, \n",
    "    min_cluster_size=200, \n",
    "    min_samples=7         \n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compared to DBSCAN, HDBSCAN creates a more balanced distribution of clusters, with a more uniform size of clusters. But we have 2 groups that are bigger than the others, which is not a good solution for this dataset.",
   "id": "f73f0bf20c6db78b"
  },
  {
   "cell_type": "markdown",
   "id": "75608ff5",
   "metadata": {},
   "source": [
    "#### 7.1.4 Mean-shift"
   ]
  },
  {
   "cell_type": "code",
   "id": "24d9bb16",
   "metadata": {},
   "source": [
    "df_value_meanshift= customer.copy()\n",
    "df_value_meanshift['Cluster_MS_val'] = get_meanshift(customer, features_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "422c2705",
   "metadata": {},
   "source": [
    "print(df_value_meanshift.groupby('Cluster_MS_val')[features_val].mean())\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(df_value_meanshift.groupby('Cluster_MS_val').size())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "212dc2aa",
   "metadata": {},
   "source": [
    "#### 7.1.5 Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c1d0349",
   "metadata": {},
   "source": [
    "df_value_gaussian_mix_model= customer.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6dba254",
   "metadata": {},
   "source": [
    "get_n_components(df_value_gaussian_mix_model, features_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f31f6fa1",
   "metadata": {},
   "source": [
    "The optimal number of components ($K$) for the Gaussian Mixture Model was determined by minimizing the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC). These metrics were evaluated for both Diagonal and Full covariance structures across a range of 1 to 10 components.\n",
    "\n",
    "The **Full Covariance** structure is strictly superior to the Diagonal structure for this dataset.\n",
    "* **Magnitude of Error:** The Full Covariance model achieves criterion scores as low as ~25,000. In contrast, the Diagonal model’s best score is significantly higher, being around ~40,000.\n",
    "* **Implication:** The substantial gap in scores confirms that the features in the dataset are correlated. The Diagonal model's assumption of independence is too restrictive and fails to capture the true shape of the data.\n",
    "\n",
    "**Component Selection (Full Covariance)**\n",
    "The Full Covariance plot exhibits a distinct \"stepped\" pattern rather than a smooth curve, revealing the hierarchical nature of the data:\n",
    "* **Primary Structure ($K=6$):** A sharp, continuous reduction in AIC/BIC is observed up to 6 components, followed by a distinct **plateau** from $K=6$ to $K=8$. This indicates that 6 clusters are sufficient to capture the coarse, high-level structure of the data.\n",
    "\n",
    "\n",
    "**Decision:** A **Full Covariance GMM with 6 components** is selected to prioritize strategic applicability and model parsimony."
   ]
  },
  {
   "cell_type": "code",
   "id": "313b8a59",
   "metadata": {},
   "source": [
    "gmm_model_value, df_concat_value = fit_gmm_segmentation(df_value_gaussian_mix_model, features_val, k=7, rsq_func=get_rsq)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58c1a72a",
   "metadata": {},
   "source": [
    "analyze_gmm_uncertainty(gmm_model_value, df_value_gaussian_mix_model, features_val, threshold=0.8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5d404cfd",
   "metadata": {},
   "source": [
    "**Uncertainty Analysis**\n",
    "* **Threshold:** A strict confidence threshold of **80%** was applied to test the robustness of the clusters.\n",
    "* **Results:** The model successfully classified **83.6%** of customers (12,533) with high confidence. The remaining **16.4%** (2,456 customers) lie in the \"boundary\" regions between clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b88721",
   "metadata": {},
   "source": [
    "#### 7.1.6 SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09caadfa",
   "metadata": {},
   "source": [
    "##### 7.1.6.1 Component planes and U-matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "cdfa3458",
   "metadata": {},
   "source": [
    "grid_size = 12\n",
    "features_to_use = features_val\n",
    "\n",
    "# Inicializar e Treinar\n",
    "som_val = MiniSom(x=grid_size, y=grid_size, input_len=len(features_to_use),\n",
    "                  topology='hexagonal', sigma=1.0, learning_rate=0.5,\n",
    "                  random_seed=42)\n",
    "\n",
    "som_val.pca_weights_init(customer[features_to_use].values)\n",
    "som_val.train_batch(customer[features_to_use].values, 20000, verbose=True)\n",
    "\n",
    "weights_val = som_val.get_weights()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Sugestão Bruna Ver\n",
    "\"\"\"\n",
    "\n",
    "X = customer[features_to_use].values.astype(np.float32)\n",
    "\n",
    "som_val = MiniSom(\n",
    "    x=grid_size, y=grid_size,\n",
    "    input_len=X.shape[1],\n",
    "    topology='hexagonal',\n",
    "    sigma=1.0,\n",
    "    learning_rate=0.5,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "som_val.random_weights_init(X)\n",
    "som_val.train_random(X, 3000, verbose=False)\n",
    "\n",
    "weights_val = som_val.get_weights()"
   ],
   "id": "3a815deb13ae2054",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bec99006",
   "metadata": {},
   "source": [
    "n_plots = len(features_to_use)\n",
    "n_cols = 2 \n",
    "n_rows = math.ceil(n_plots / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature_name in enumerate(features_to_use):\n",
    "    # Extrair os pesos desta variável\n",
    "    feature_weights = weights_val[:, :, i]\n",
    "    \n",
    "    # Desenhar o mapa (assumindo que já tens a função plot_hexagons carregada)\n",
    "    plot_hexagons(feature_weights, som_val, axes[i], label=feature_name, cmap=cm.Spectral_r)\n",
    "\n",
    "plt.suptitle(\"Component Planes: Value Perspective\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fbfcbee2",
   "metadata": {},
   "source": [
    "**Income & CLV**: The Income and CLV maps display a near-perfect visual match, with identical \"hotspots\" in the same regions. This confirms a strong positive correlation: our most affluent customers are directly translating their purchasing power into long-term value.\n",
    "\n",
    "**Tenure**: The Tenure map is predominantly red, indicating that the vast majority of the customer base consists of long-term loyalists. However, the distinct blue zones in the top-left and bottom-right corners represent recent acquisitions (New Customers). Crucially, these \"blue\" areas overlap with lower-income zones on the other maps, suggesting that new customers are entering at lower value tiers compared to the established \"VIP\" veterans.\n",
    "\n",
    " **Points Utilization Rate**: The Points Utilization Rate map shows a distinct pattern, mostly blue/green with isolated red pockets that do not perfectly align with the highest Income areas. This indicates that points engagement is a specific behavior driven by a \"Smart Redeemer\" niche, rather than being a universal trait of wealthy customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3144afd6",
   "metadata": {},
   "source": [
    "plot_som_diagnostics(som_val, customer[features_val].values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "638c5dde",
   "metadata": {},
   "source": [
    "The diagnostic plots reveal a strictly polarized customer base. The Hits Map identifies two major density centers: a massive cluster in the top-left (correlated with Mass Market/Lower Value profiles) and a secondary, dense cluster in the bottom-right (High Value).\n",
    "\n",
    "Crucially, the U-Matrix shows clear high-distance barriers (red zones) surrounding the bottom-right cluster. This confirms that our High-Value customers form a distinct 'island' with unique characteristics, completely separate from the general customer population. This separation justifies a dedicated, exclusive marketing strategy for this group, as they do not share behaviors with the rest of the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b24e9",
   "metadata": {},
   "source": [
    "##### 7.1.6.2 SOMS with K-means"
   ]
  },
  {
   "cell_type": "code",
   "id": "3d064e0c",
   "metadata": {},
   "source": [
    "labels_som_val = run_som_kmeans(som_val, customer[features_val].values, n_clusters=5) # we tried n_clusters=4 first"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "26cf30e0",
   "metadata": {},
   "source": [
    "Initial validation metrics (Elbow Method, Silhouette Analysis) suggested an optimal structure of k=4. However, visual inspection of the SOM projection highlighted a critical limitation in this configuration: the 'New Customer' cluster was aggregating two financially opposing profiles (High vs. Low Income) solely based on their shared low tenure. Therefore, we opted for a k=5 solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4859721",
   "metadata": {},
   "source": [
    "The map now clearly delineates 5 core segments:\n",
    "\n",
    "Yellow (Top-Left): \"Low-Value Newcomers.\" Recent acquisitions with low spending power. \n",
    "\n",
    "Orange (Bottom-Right): \"High-Potential Newcomers.\" Recent acquisitions with high income and CLV. \n",
    "\n",
    "Burgundy (Bottom-Left): \"Loyal Veterans.\" The stable, long-term high-value core. \n",
    "\n",
    "Purple (Top/Center): \"Mass Market.\" High volume but lower individual margins. \n",
    "\n",
    "Green (Right/Center): \"Transitional.\" Middle-tier customers showing potential for growth. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f116aa1",
   "metadata": {},
   "source": [
    "The fact that the clusters appear as solid, contiguous regions (rather than scattered noise) confirms that the K-Means algorithm has identified genuine, well-separated patterns in the customer behavior, rather than forcing arbitrary divisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83373c",
   "metadata": {},
   "source": [
    "##### 7.1.6.3 SOMS with Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "id": "c4d28641",
   "metadata": {},
   "source": [
    "run_som_hierarchical(som_val, n_clusters=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89e9fc83",
   "metadata": {},
   "source": [
    "The Hierarchical Clustering projection (Ward linkage) produces a topological map nearly identical to the K-Means solution. This convergence between two mathematically distinct algorithms confirms that the 5-cluster structure is stable, natural, and robust. The Dendrogram displays a deep hierarchical split, validating the decision to use k=5. The distinct vertical branches prove that the 5 groups are well-separated in the data space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e2d4d",
   "metadata": {},
   "source": [
    "The SOM successfully transformed complex multidimensional data into an interpretable 2D map organized by behavioral similarity.\n",
    "\n",
    "The most significant outcome was the visual diagnosis of the \"New Customer\" segment. While standard statistics grouped all recent acquisitions together, the SOM geographically separated them into High-Potential and Low-Value zones. This insight was the decisive factor in refining the segmentation from 4 to 5 clusters, allowing for a differentiated retention strategy.\n",
    "\n",
    "Hits Map demonstrated a healthy data distribution without signs of overfitting. The structural consistency was further validated by the convergence with Hierarchical Clustering results, proving the model is stable and reliable for decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e62de",
   "metadata": {},
   "source": [
    "#### Value segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "id": "88a880f7",
   "metadata": {},
   "source": [
    "X_value = customer[features_val]\n",
    "kmeans_final = KMeans(n_clusters=5, init='k-means++', n_init=20, random_state=42)\n",
    "labels_kmeans = kmeans_final.fit_predict(X_value)\n",
    "\n",
    "metrics_kmeans = get_model_metrics(\n",
    "    df=X_value,\n",
    "    labels=labels_kmeans,\n",
    "    model_name=\"K-Means (k=4)\",\n",
    "    perspective=\"Value\"\n",
    ")\n",
    "results_value.append(metrics_kmeans)\n",
    "\n",
    "\n",
    "# --- 2. Hierarchical (Agglomerative) - Ward, k=5 ---\n",
    "\n",
    "#hc_final = AgglomerativeClustering(n_clusters=5, metric='euclidean', linkage='ward')\n",
    "#labels_hc = hc_final.fit_predict(X_value)\n",
    "#metrics_hc = get_model_metrics(\n",
    "#    df=X_value,\n",
    "#    labels=labels_hc,\n",
    "#    model_name=\"Hierarchical (Ward, k=5)\",\n",
    "#    perspective=\"Value\"\n",
    "#)\n",
    "#results_value.append(metrics_hc)\n",
    "\n",
    "\n",
    "# --- 3. DBSCAN  ---\n",
    "\n",
    "metrics_dbscan = get_model_metrics(\n",
    "    df=X_value,\n",
    "    labels=labels_val, \n",
    "    model_name=\"DBSCAN (eps=0.35)\",\n",
    "    perspective=\"Value\"\n",
    ")\n",
    "results_value.append(metrics_dbscan)\n",
    "\n",
    "\n",
    "# --- 4. HDBSCAN  ---\n",
    "metrics_hdb = get_model_metrics(\n",
    "    df=X_value,\n",
    "    labels=labels_hdb_val,\n",
    "    model_name=\"HDBSCAN (min_cluster=200)\",\n",
    "    perspective=\"Value\"\n",
    ")\n",
    "results_value.append(metrics_hdb)\n",
    "\n",
    "\n",
    "# --- 5. Mean Shift ---\n",
    "metrics_ms = get_model_metrics(\n",
    "    df=X_value,\n",
    "    labels=df_value_meanshift['Cluster_MS_val'],\n",
    "    model_name=\"Mean Shift\",\n",
    "    perspective=\"Value\"\n",
    ")\n",
    "results_value.append(metrics_ms)\n",
    "\n",
    "\n",
    "# --- 6. Gaussian Mixture (GMM, k=14) ---\n",
    "\n",
    "labels_value_gmm = gmm_model_value.predict(X_value)\n",
    "\n",
    "metrics_gmm = get_model_metrics(\n",
    "    df=X_value,\n",
    "    labels=labels_value_gmm,\n",
    "    model_name=\"GMM (k=14)\",\n",
    "    perspective=\"Value\"\n",
    ")\n",
    "results_value.append(metrics_gmm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26b856a6",
   "metadata": {},
   "source": [
    "df_compare_value = pd.DataFrame(results_value)\n",
    "df_compare_value = df_compare_value.sort_values(by='Silhouette Score', ascending=False)\n",
    "df_compare_value"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1435dd50",
   "metadata": {},
   "source": [
    "### 7.2 Behavioral Segmentation perspective"
   ]
  },
  {
   "cell_type": "code",
   "id": "37eb10cee4576504",
   "metadata": {},
   "source": [
    "features_behave = clustering_perspectives['Behavioral_Segmentation']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d08fd26",
   "metadata": {},
   "source": [
    "results_behave = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44257165",
   "metadata": {},
   "source": [
    "#### 7.2.1 K-means with Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "id": "a81873b2",
   "metadata": {},
   "source": [
    "df_behave_kmeans_hc = customer[features_behave].copy()\n",
    "df_behave_kmeans_hc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf0efd6f",
   "metadata": {},
   "source": [
    "df_behave_sample = df_behave_kmeans_hc.sample(n=5000, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "138bb58a",
   "metadata": {},
   "source": [
    "r2_scores_behave = {}\n",
    "\n",
    "r2_scores_behave['kmeans'] = func.get_r2_scores(df_behave_sample, df_behave_kmeans_hc.columns.tolist(), kmeans)\n",
    "\n",
    "for linkage in ['complete', 'average', 'single', 'ward']: # 4 different versions of HC\n",
    "    r2_scores_behave[linkage] = func.get_r2_scores(\n",
    "        df_behave_sample,                 # data\n",
    "        df_behave_kmeans_hc.columns.tolist(),   # features of perspective\n",
    "        # use HClust, changing the linkage at each iteration\n",
    "        hierarchical.set_params(linkage=linkage) \n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b1e03f4",
   "metadata": {},
   "source": [
    "r2_scores_behave = pd.DataFrame(r2_scores)\n",
    "r2_scores_behave"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5bdb62b7",
   "metadata": {},
   "source": [
    "r2_scores_df_behave = pd.DataFrame(r2_scores)\n",
    "\n",
    "r2_scores_df_behave.plot.line(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Demographic Variables:\\nR² plot for various clustering methods\\n\", fontsize=21)\n",
    "plt.legend(title=\"Cluster methods\", title_fontsize=11)\n",
    "plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "plt.ylabel(\"R² metric\", fontsize=13)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6ac7630b",
   "metadata": {},
   "source": [
    "The comparison of clustering algorithms reveals that K-Means outperforms other methods, achieving the highest explained variance across all k values. Regarding the number of clusters, we identify a elbow at k=4. The model explains mora then 60% of the behavioral variance at this point."
   ]
  },
  {
   "cell_type": "code",
   "id": "5a845662",
   "metadata": {},
   "source": [
    "df_sample_behave_viz = df_behave_kmeans_hc.sample(n=3000, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3cf9dd03",
   "metadata": {},
   "source": [
    "To optimize processing time, we will generate the Silhouette plot using a random subset of 3,000 customers."
   ]
  },
  {
   "cell_type": "code",
   "id": "bab475f1",
   "metadata": {},
   "source": [
    "func.visualize_silhouette_graf(df_sample_behave_viz, range_clusters=range(2, 11))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0d8aa34",
   "metadata": {},
   "source": "Although the Silhouette analysis indicates a mathematical peak at k=2, we rejected this solution as it results in an oversimplified binary segmentation ( merely separating high vs. low values). We selected k=5 because it offers the optimal balance between statistical validity and business utility, allowing us to identify distinct niche profiles that would otherwise be merged in a 2-cluster solution."
  },
  {
   "cell_type": "code",
   "id": "846e909f",
   "metadata": {},
   "source": [
    "kmeans_value = KMeans(\n",
    "    n_clusters=5,\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e04bdab5",
   "metadata": {},
   "source": [
    "behave_labels = kmeans_value.fit_predict(df_behave_kmeans_hc)\n",
    "behave_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7b8e4389",
   "metadata": {},
   "source": [
    "print(pd.Series(behave_labels).value_counts().sort_index())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we tried using k=4, but it didn't show a good distribution of the clusters, so we decided to use k=5 because here we can see more homogenous distribution of the clusters.",
   "id": "d1227ad072475a0f"
  },
  {
   "cell_type": "markdown",
   "id": "b6b28a2f",
   "metadata": {},
   "source": [
    "#### 7.2.2 DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "id": "5a3a78e8",
   "metadata": {},
   "source": [
    "k_behave = plot_k_distance(customer, features_behave)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2799781",
   "metadata": {},
   "source": [
    "labels_behave, n_clus_behave, dist_behave = get_dbscan(\n",
    "    customer, \n",
    "    features_behave, \n",
    "    eps=0.45,\n",
    "    min_samples=9\n",
    ")\n",
    "\n",
    "dbscan_results['Behave'] = {'Clusters': n_clus_behave, 'Distribution': dist_behave}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once again, DBSCAN didn't show a good distribution of the clusters, so we rejected this solution.",
   "id": "9ee3f1a12581bf0d"
  },
  {
   "cell_type": "markdown",
   "id": "0bd06423",
   "metadata": {},
   "source": [
    "#### 7.2.3 HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "id": "80878854",
   "metadata": {},
   "source": [
    "labels_hdb_behave, n_hdb_behave, dist_hdb_behave = func.get_hdbscan(\n",
    "    customer, \n",
    "    features_behave, \n",
    "    min_cluster_size=200, \n",
    "    min_samples=9         \n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see here the HDBSCAN solution is not a good solution for this dataset, beside the clusters being not homogenous, we also have a 43% of noise points.",
   "id": "a7b16a73b27588f2"
  },
  {
   "cell_type": "markdown",
   "id": "cb6bbaac",
   "metadata": {},
   "source": [
    "#### 7.2.4 Mean-shift"
   ]
  },
  {
   "cell_type": "code",
   "id": "7a3858d6",
   "metadata": {},
   "source": [
    "df_behave_meanshift= customer.copy()\n",
    "df_behave_meanshift['Cluster_MS_behave'] = get_meanshift(customer, features_behave)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0934baa5",
   "metadata": {},
   "source": [
    "print(df_behave_meanshift.groupby('Cluster_MS_behave')[features_behave].mean())\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(df_behave_meanshift.groupby('Cluster_MS_behave').size())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "640c3d39",
   "metadata": {},
   "source": [
    "#### 7.2.5 Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "27987544",
   "metadata": {},
   "source": [
    "df_behave_gaussian_mix_model= customer.copy()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6822e9a",
   "metadata": {},
   "source": [
    "get_n_components(df_behave_gaussian_mix_model, features_behave)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eeb77e2f",
   "metadata": {},
   "source": [
    "The **Full Covariance** structure is generally superior to the Diagonal structure for this dataset.\n",
    "* **Magnitude of Error:** The Full Covariance model achieves criterion scores dropping rapidly to around -65,000 at $K=3$ and reaching lows near -120,000 at $K=10$. The Diagonal model shows a similar trend but generally lags in performance, requiring more components to achieve similar fit levels.\n",
    "* **Implication:** The better performance of the Full Covariance model confirms that the features in this subset are correlated. The Diagonal model's assumption of independence is too restrictive to efficiently capture the data's shape with a small number of clusters.\n",
    "\n",
    "**Component Selection (Full Covariance)**\n",
    "The Full Covariance plot exhibits a very distinct and early **\"Elbow\" pattern**:\n",
    "* **Initial Drop ($K=1$ to $K=3$):** A precipitous reduction in AIC/BIC values is observed from 1 to 3 components. The score drops vertically from ~140,000 to roughly -65,000, indicating that the vast majority of the data's structure is captured by just three primary archetypes.\n",
    "* **The \"Elbow\" ($K=3$):** The curve flattens noticeably at **3 components**. While the score continues to decrease slowly towards $K=5$ and beyond, the rate of improvement slows down dramatically after the third component.\n",
    "* **Diminishing Returns:** Beyond $K=3$, the curve transitions into a gentler slope. The massive strategic gain happens in the first three clusters, suggesting that adding further complexity yields diminishing returns relative to the increased model complexity.\n",
    "\n",
    "**Decision:** A **Full Covariance GMM with 3 components** is selected to prioritize interpretability and capture the core structure of the data without over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "id": "ecafa450",
   "metadata": {},
   "source": [
    "gmm_model_behave, df_concat_behave = fit_gmm_segmentation(df_behave_gaussian_mix_model, features_behave, k=3, rsq_func=get_rsq)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b6661de",
   "metadata": {},
   "source": [
    "analyze_gmm_uncertainty(gmm_model_behave, df_behave_gaussian_mix_model, features_behave, threshold=0.99)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b668953c",
   "metadata": {},
   "source": [
    "**Uncertainty Analysis**\n",
    "* **Threshold:** An extremely strict confidence threshold of **99%** was applied to test the robustness of the clusters.\n",
    "* **Results:** The model demonstrated nearly perfect separation, as shown by the dense concentration of assignment probabilities above 0.995. The vast majority of customers fall into the \"confident\" region, with negligible uncertainty found even at this stringent cutoff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2e782",
   "metadata": {},
   "source": [
    "#### 7.2.6 SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db4971",
   "metadata": {},
   "source": [
    "##### 7.2.6.1 Component planes and U-matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "7561540e",
   "metadata": {},
   "source": [
    "grid_size = 12\n",
    "features_to_use = features_behave\n",
    "\n",
    "# Inicializar e Treinar\n",
    "som_behave = MiniSom(x=grid_size, y=grid_size, input_len=len(features_to_use),\n",
    "                  topology='hexagonal', sigma=1.0, learning_rate=0.5,\n",
    "                  random_seed=42)\n",
    "\n",
    "som_behave.pca_weights_init(customer[features_to_use].values)\n",
    "som_behave.train_batch(customer[features_to_use].values, 20000, verbose=True)\n",
    "\n",
    "weights_behave = som_behave.get_weights()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f98763a",
   "metadata": {},
   "source": [
    "n_plots = len(features_behave)\n",
    "n_cols = 3 \n",
    "n_rows = math.ceil(n_plots / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 4. Loop through features and plot\n",
    "for i, feature_name in enumerate(features_behave):\n",
    "    # Extract weights for this specific feature\n",
    "    feature_weights = weights_behave[:, :, i]\n",
    "    \n",
    "    # Plot the hexagon map\n",
    "    # Using Spectral_r: Red = High Values, Blue = Low Values\n",
    "    plot_hexagons(feature_weights, som_behave, axes[i], label=feature_name, cmap=cm.Spectral_r)\n",
    "\n",
    "# 5. Hide the empty subplot (since we have 5 plots for 6 spaces)\n",
    "for j in range(n_plots, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.suptitle(\"Component Planes: Behavioral Perspective\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa3d0035",
   "metadata": {},
   "source": [
    "There is a clear inverse relationship. The customers who fly the most (Left) almost always fly alone (Low Companion Ratio). Conversely, the customers on the Right fly less often but travel in groups. Also, High-frequency flyers (Left) are not necessarily flying far; they might be taking short, frequent domestic hops. The \"Long-Haul\" customers are a distinct group, likely taking fewer but much more expensive intercontinental trips. The recency-months map is predominantly blue/green, indicating a generally active customer base. In the flight_trend_scope we can notice the blue patches on the Left (Frequent Flyers). This suggests some of your best customers are slowing down their activity (Negative Slope)"
   ]
  },
  {
   "cell_type": "code",
   "id": "999aeba4",
   "metadata": {},
   "source": [
    "plot_som_diagnostics(som_behave, customer[features_behave].values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "72507830",
   "metadata": {},
   "source": [
    "##### 7.2.6.2 SOMS with K-means"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc82b01c",
   "metadata": {},
   "source": [
    "labels_som_behave = run_som_kmeans(som_behave, customer[features_behave].values, n_clusters=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15ac52c2",
   "metadata": {},
   "source": [
    "##### 7.2.6.3 SOMS with Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "id": "8fcfb78a",
   "metadata": {},
   "source": [
    "run_som_hierarchical(som_behave, n_clusters=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "324b5ea2",
   "metadata": {},
   "source": [
    "#### Behavioral segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b991910",
   "metadata": {},
   "source": [
    "X_behave = customer[features_behave]\n",
    "kmeans_final = KMeans(n_clusters=4, init='k-means++', n_init=20, random_state=42)\n",
    "labels_kmeans = kmeans_final.fit_predict(X_behave)\n",
    "\n",
    "metrics_kmeans = get_model_metrics(\n",
    "    df=X_behave,\n",
    "    labels=labels_kmeans,\n",
    "    model_name=\"K-Means (k=5)\",\n",
    "    perspective=\"Behavioral\"\n",
    ")\n",
    "results_behave.append(metrics_kmeans)\n",
    "\n",
    "\n",
    "# --- 2. Hierarchical (Agglomerative) - Ward, k=5 ---\n",
    "\n",
    "#hc_final = AgglomerativeClustering(n_clusters=5, metric='euclidean', linkage='ward')\n",
    "#labels_hc = hc_final.fit_predict(X_value)\n",
    "#metrics_hc = get_model_metrics(\n",
    "#    df=X_value,\n",
    "#    labels=labels_hc,\n",
    "#    model_name=\"Hierarchical (Ward, k=5)\",\n",
    "#    perspective=\"Value\"\n",
    "#)\n",
    "#results_value.append(metrics_hc)\n",
    "\n",
    "\n",
    "# --- 3. DBSCAN  --- SO TEM DOIS CLUSTERS\n",
    "\n",
    "#metrics_dbscan = get_model_metrics(\n",
    "    #df=X_behave,\n",
    "    #labels=labels_behave, \n",
    "    #model_name=\"DBSCAN (eps=0.45)\",\n",
    "    #perspective=\"Behavioral\"\n",
    "#)\n",
    "#results_behave.append(metrics_dbscan)\n",
    "\n",
    "\n",
    "# --- 4. HDBSCAN  ---\n",
    "metrics_hdb = get_model_metrics(\n",
    "    df=X_behave,\n",
    "    labels=labels_hdb_behave,\n",
    "    model_name=\"HDBSCAN (min_cluster=200)\",\n",
    "    perspective=\"Behavioral\"\n",
    ")\n",
    "results_behave.append(metrics_hdb)\n",
    "\n",
    "\n",
    "# --- 5. Mean Shift ---\n",
    "metrics_ms = get_model_metrics(\n",
    "    df=X_behave,\n",
    "    labels=df_behave_meanshift['Cluster_MS_behave'],\n",
    "    model_name=\"Mean Shift\",\n",
    "    perspective=\"Behavioral\"\n",
    ")\n",
    "results_behave.append(metrics_ms)\n",
    "\n",
    "\n",
    "# --- 6. Gaussian Mixture ---\n",
    "\n",
    "labels_value_gmm = gmm_model_behave.predict(X_behave)\n",
    "\n",
    "metrics_gmm = get_model_metrics(\n",
    "    df=X_behave,\n",
    "    labels=labels_value_gmm,\n",
    "    model_name=\"GMM (k=7)\",\n",
    "    perspective=\"Behavioral\"\n",
    ")\n",
    "results_behave.append(metrics_gmm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a3897d1c",
   "metadata": {},
   "source": [
    "df_compare_behave = pd.DataFrame(results_behave)\n",
    "df_compare_behave = df_compare_behave.sort_values(by='Silhouette Score', ascending=False)\n",
    "df_compare_behave"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "10af21ed8e1e0ec5",
   "metadata": {},
   "source": [
    "### 7.3 Seasonality Segmentation Perspective"
   ]
  },
  {
   "cell_type": "code",
   "id": "af98da278106ecc2",
   "metadata": {},
   "source": [
    "features_season = clustering_perspectives['Seasonality_Segmentation']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6bffeee6",
   "metadata": {},
   "source": [
    "results_season = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f871127939d0ea4d",
   "metadata": {},
   "source": [
    "#### 7.3.1 K-means with Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "id": "76101343a5d4f50a",
   "metadata": {},
   "source": [
    "df_season_kmeans_hc = customer[features_season].copy()\n",
    "df_season_kmeans_hc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44285047281cb990",
   "metadata": {},
   "source": [
    "df_season_sample = df_season_kmeans_hc.sample(n=5000, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fee3644c8080af13",
   "metadata": {},
   "source": [
    "r2_scores_season = {}\n",
    "\n",
    "df_season_sample = df_season_kmeans_hc.sample(n=5000, random_state=42)\n",
    "r2_scores_season['kmeans'] = func.get_r2_scores(df_season_sample, df_season_kmeans_hc.columns.tolist(), kmeans)\n",
    "\n",
    "for linkage in ['complete', 'average', 'single', 'ward']: # 4 different versions of HC\n",
    "    r2_scores_season[linkage] = func.get_r2_scores(\n",
    "        df_season_sample,                 # data\n",
    "        df_season_kmeans_hc.columns.tolist(),   # features of perspective\n",
    "        # use HClust, changing the linkage at each iteration\n",
    "        hierarchical.set_params(linkage=linkage)\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4ce4f15",
   "metadata": {},
   "source": [
    "r2_scores_season = pd.DataFrame(r2_scores)\n",
    "r2_scores_season"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4346b03b51163733",
   "metadata": {},
   "source": [
    "r2_scores_df_season = pd.DataFrame(r2_scores)\n",
    "\n",
    "r2_scores_df_season.plot.line(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Demographic Variables:\\nR² plot for various clustering methods\\n\", fontsize=21)\n",
    "plt.legend(title=\"Cluster methods\", title_fontsize=11)\n",
    "plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "plt.ylabel(\"R² metric\", fontsize=13)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Again, when the topic of we are talking about is comparison of clustering algorithms, K-Means outperforms other methods, achieving the highest explained variance across all k values. Regarding the number of clusters, we identify a elbow at k=4 one more time. It's not a surprise the 4 cluster since we have 4 diferents seasonality.",
   "id": "9f559f44f1ae9bb4"
  },
  {
   "cell_type": "code",
   "id": "102bd46f50b0a1b4",
   "metadata": {},
   "source": [
    "df_sample_season_viz = df_season_kmeans_hc.sample(n=3000, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ccbe4dff3849120",
   "metadata": {},
   "source": [
    "func.visualize_silhouette_graf(df_sample_season_viz, range_clusters=range(2, 11))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The silhouette score for k=3 is the highest, whats its strange, because does not confirm that 4 clusters is the optimal choice for this dataset. In the future we should try to use k = 3 and k = 4 just to see what generates better homogeneous distribution.",
   "id": "3fcb382043f13071"
  },
  {
   "cell_type": "code",
   "id": "e4d2d9a5",
   "metadata": {},
   "source": [
    "kmeans_season = KMeans(\n",
    "    n_clusters=4,\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94694d17",
   "metadata": {},
   "source": [
    "season_labels = kmeans_season.fit_predict(df_season_kmeans_hc)\n",
    "season_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "004b5824",
   "metadata": {},
   "source": [
    "print(pd.Series(season_labels).value_counts().sort_index())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With k=3, the distribution showed a large peak in one of the clusters, which didn’t make sense. With k=4, the distribution was more balanced. Considering the graph of the number of flights per month and per year, there were two major peaks that likely correspond to the two largest clusters, while the other clusters represented smaller seasonal peaks.",
   "id": "f41823fef1eec0fa"
  },
  {
   "cell_type": "markdown",
   "id": "c0b9adebbfb6684",
   "metadata": {},
   "source": [
    "#### 7.3.2 DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0a4c527",
   "metadata": {},
   "source": [
    "k_season = plot_k_distance(customer, features_season)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "256692cb",
   "metadata": {},
   "source": [
    "labels_season, n_clus_season, dist_season = get_dbscan(\n",
    "    customer, \n",
    "    features_season, \n",
    "    eps=0.35,\n",
    "    min_samples=9\n",
    ")\n",
    "\n",
    "dbscan_results['Season'] = {'Clusters': n_clus_season, 'Distribution': dist_season}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "DBSCAN shows us again that it is not a good option for this dataset, because of a large pick in one cluster, and a poor distribution of the other clusters.",
   "id": "9d6201348a7e60ee"
  },
  {
   "cell_type": "markdown",
   "id": "ec57cb628b369d2e",
   "metadata": {},
   "source": [
    "#### 7.3.3 HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "id": "add9ef0b",
   "metadata": {},
   "source": [
    "labels_hdb_season, n_hdb_season, dist_hdb_season = func.get_hdbscan(\n",
    "    customer, \n",
    "    features_season, \n",
    "    min_cluster_size=200, \n",
    "    min_samples=9         \n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "HDBSCAN goes in the same way of the DBSCAN, shows us again that it is not a good option for this dataset, because of a large pick in one cluster, and a poor distribution of the other clusters.",
   "id": "52a86ee29c93ff57"
  },
  {
   "cell_type": "markdown",
   "id": "cd28059bbd0272e6",
   "metadata": {},
   "source": [
    "#### 7.3.4 Mean-shift"
   ]
  },
  {
   "cell_type": "code",
   "id": "87a37d35288fee3f",
   "metadata": {},
   "source": [
    "df_season_meanshift= customer.copy()\n",
    "df_season_meanshift['Cluster_MS_season'] = get_meanshift(customer, features_season)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "659217e4b394d40e",
   "metadata": {},
   "source": [
    "print(df_season_meanshift.groupby('Cluster_MS_season')[features_season].mean())\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(df_season_meanshift.groupby('Cluster_MS_season').size())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2aba872c51051ad2",
   "metadata": {},
   "source": [
    "#### 7.3.5 Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "56b9ad72",
   "metadata": {},
   "source": [
    "df_season_gaussian_mix_model= customer.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e837e8a",
   "metadata": {},
   "source": [
    "get_n_components(df_season_gaussian_mix_model, features_season)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e59bf49e",
   "metadata": {},
   "source": [
    "The **Full Covariance** structure is strictly superior to the Diagonal structure for this dataset.\n",
    "* **Magnitude of Error:** The Full Covariance model achieves extremely low criterion scores, reaching approximately **-150,000**. In contrast, the Diagonal model performs significantly worse, with scores remaining positive (lowest around **12,000**).\n",
    "* **Implication:** The massive difference in scores confirms that the features are intrinsically linked. The Diagonal model's assumption of independence is invalid for this data.\n",
    "\n",
    "**Component Selection (Full Covariance)**\n",
    "The Full Covariance plot exhibits a sharp **\"Elbow\" pattern** that supports the selection of 3 clusters:\n",
    "* **Precipitous Drop ($K=1$ to $K=2$):** The AIC/BIC values plummet vertically, indicating the first split captures the massive bulk of variance.\n",
    "* **The \"Elbow\" ($K=3$):** A significant improvement continues up to **3 components**, reaching a score near **-145,000**. While $K=4$ offers a slight improvement, the curve begins to flatten noticeably after $K=3$, indicating the primary structures are identified.\n",
    "* **Diminishing Returns:** Beyond $K=3$, the rate of improvement slows down drastically compared to the initial drops. The model stabilizes, suggesting that adding more complexity yields marginal statistical gain.\n",
    "\n",
    "**Decision:** A **Full Covariance GMM with 3 components** is selected as the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "id": "180de0a8",
   "metadata": {},
   "source": [
    "gmm_model_season, df_concat_season = fit_gmm_segmentation(df_season_gaussian_mix_model, features_season, k=3, rsq_func=get_rsq)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "869a476c",
   "metadata": {},
   "source": [
    "analyze_gmm_uncertainty(gmm_model_season, df_season_gaussian_mix_model, features_season, threshold=0.99)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0faf6fc0",
   "metadata": {},
   "source": [
    "**Uncertainty Analysis**\n",
    "* **Threshold:** A rigorous confidence threshold of **99%** was applied to evaluate the clarity of the seasonal segments.\n",
    "* **Results:** The model successfully classified **14,951 customers** with clear confidence. Only **38 customers** (**0.3%**) were flagged as uncertain. This exceptionally low uncertainty indicates that the identified seasonal behaviors are highly distinct, with almost no ambiguity in customer assignment even at a very strict threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ceda1",
   "metadata": {},
   "source": [
    "#### 7.3.6 SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee811c",
   "metadata": {},
   "source": [
    "##### 7.3.6.1 Component planes and U-matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab20e461",
   "metadata": {},
   "source": [
    "grid_size = 12\n",
    "features_to_use = features_season\n",
    "\n",
    "# Inicializar e Treinar\n",
    "som_season = MiniSom(x=grid_size, y=grid_size, input_len=len(features_to_use),\n",
    "                  topology='hexagonal', sigma=1.0, learning_rate=0.5,\n",
    "                  random_seed=42)\n",
    "\n",
    "som_season.pca_weights_init(customer[features_to_use].values)\n",
    "som_season.train_batch(customer[features_to_use].values, 20000, verbose=True)\n",
    "\n",
    "weights_season = som_season.get_weights()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "deca901e",
   "metadata": {},
   "source": [
    "n_plots = len(features_season)\n",
    "n_cols = 3 \n",
    "n_rows = math.ceil(n_plots / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 4. Loop through features and plot\n",
    "for i, feature_name in enumerate(features_season):\n",
    "    # Extract weights for this specific feature\n",
    "    feature_weights = weights_season[:, :, i]\n",
    "    \n",
    "    # Plot the hexagon map\n",
    "    # Using Spectral_r: Red = High Values, Blue = Low Values\n",
    "    plot_hexagons(feature_weights, som_season, axes[i], label=feature_name, cmap=cm.Spectral_r)\n",
    "\n",
    "# 5. Hide the empty subplot (since we have 5 plots for 6 spaces)\n",
    "for j in range(n_plots, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.suptitle(\"Component Planes: Seasonality Perspective\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2296bcae",
   "metadata": {},
   "source": [
    "plot_som_diagnostics(som_season, customer[features_season].values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59f525ba",
   "metadata": {},
   "source": [
    "##### 7.3.6.2 SOMS with K-means"
   ]
  },
  {
   "cell_type": "code",
   "id": "f626f61a",
   "metadata": {},
   "source": [
    "labels_som_season = run_som_kmeans(som_season, customer[features_season].values, n_clusters=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8804097f",
   "metadata": {},
   "source": [
    "##### 7.3.6.3 SOMS with Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "id": "577ee60f",
   "metadata": {},
   "source": [
    "run_som_hierarchical(som_season, n_clusters=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92e63f98",
   "metadata": {},
   "source": [
    "#### Seasonality Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "5bdb305d",
   "metadata": {},
   "source": [
    "X_season = customer[features_season]\n",
    "kmeans_final = KMeans(n_clusters=4, init='k-means++', n_init=20, random_state=42)\n",
    "labels_kmeans = kmeans_final.fit_predict(X_season)\n",
    "\n",
    "metrics_kmeans = get_model_metrics(\n",
    "    df=X_season,\n",
    "    labels=labels_kmeans,\n",
    "    model_name=\"K-Means (k=4)\",\n",
    "    perspective=\"Seasonality\"\n",
    ")\n",
    "results_season.append(metrics_kmeans)\n",
    "\n",
    "\n",
    "# --- 2. Hierarchical (Agglomerative) - Ward, k=5 ---\n",
    "\n",
    "#hc_final = AgglomerativeClustering(n_clusters=5, metric='euclidean', linkage='ward')\n",
    "#labels_hc = hc_final.fit_predict(X_value)\n",
    "#metrics_hc = get_model_metrics(\n",
    "#    df=X_value,\n",
    "#    labels=labels_hc,\n",
    "#    model_name=\"Hierarchical (Ward, k=5)\",\n",
    "#    perspective=\"Value\"\n",
    "#)\n",
    "#results_value.append(metrics_hc)\n",
    "\n",
    "\n",
    "# --- 3. DBSCAN  ---\n",
    "\n",
    "metrics_dbscan = get_model_metrics(\n",
    "    df=X_season,\n",
    "    labels=labels_season, \n",
    "    model_name=\"DBSCAN (eps=0.35)\",\n",
    "    perspective=\"Seasonality\"\n",
    ")\n",
    "results_season.append(metrics_dbscan)\n",
    "\n",
    "\n",
    "# --- 4. HDBSCAN  ---\n",
    "metrics_hdb = get_model_metrics(\n",
    "    df=X_season,\n",
    "    labels=labels_hdb_season,\n",
    "    model_name=\"HDBSCAN (min_cluster=200)\",\n",
    "    perspective=\"Seasonality\"\n",
    ")\n",
    "results_season.append(metrics_hdb)\n",
    "\n",
    "\n",
    "# --- 5. Mean Shift ---\n",
    "metrics_ms = get_model_metrics(\n",
    "    df=X_season,\n",
    "    labels=df_season_meanshift['Cluster_MS_season'],\n",
    "    model_name=\"Mean Shift\",\n",
    "    perspective=\"Seasonality\"\n",
    ")\n",
    "results_season.append(metrics_ms)\n",
    "\n",
    "\n",
    "# --- 6. Gaussian Mixture ---\n",
    "\n",
    "labels_season_gmm = gmm_model_season.predict(X_season)\n",
    "\n",
    "metrics_gmm = get_model_metrics(\n",
    "    df=X_season,\n",
    "    labels=labels_season_gmm,\n",
    "    model_name=\"GMM (k=4)\",\n",
    "    perspective=\"Seasonality\"\n",
    ")\n",
    "results_season.append(metrics_gmm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45bdc290",
   "metadata": {},
   "source": [
    "df_compare_season = pd.DataFrame(results_season)\n",
    "df_compare_season = df_compare_behave.sort_values(by='Silhouette Score', ascending=False)\n",
    "df_compare_season"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44ffa33c",
   "metadata": {},
   "source": [
    "### 7.4 Final Clustering Solution"
   ]
  },
  {
   "cell_type": "code",
   "id": "98d0e193",
   "metadata": {},
   "source": [
    "\n",
    "kmeans_value = KMeans(\n",
    "    n_clusters=4,\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")\n",
    "#value_labels = kmeans_value.fit_predict(df_value)\n",
    "#value_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a70ef8e",
   "metadata": {},
   "source": [
    "#customer['value_cluster'] = value_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f32acbd9",
   "metadata": {},
   "source": [
    "kmeans_behave = KMeans(\n",
    "    n_clusters=3,\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")\n",
    "#behave_labels = kmeans_behave.fit_predict(df_behave)\n",
    "#behave_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "05105ad2",
   "metadata": {},
   "source": [
    "#customer['behavioral_cluster'] = behave_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62df68a6",
   "metadata": {},
   "source": [
    "#print(f\"Behavioral clusters: {customer['value_cluster'].nunique()}\")\n",
    "#print(f\"Preference clusters: {customer['behavioral_cluster'].nunique()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d5d6a01a",
   "metadata": {},
   "source": [
    "#crosstab = pd.crosstab(customer['value_cluster'], customer['behavioral_cluster'])\n",
    "#crosstab"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27f59518",
   "metadata": {},
   "source": [
    "reavaliar os graficos seguintes apos o features selection"
   ]
  },
  {
   "cell_type": "code",
   "id": "418a17e9",
   "metadata": {},
   "source": [
    "cols_value = df_value.columns.tolist() \n",
    "temp_df = customer[cols_value].copy()\n",
    "temp_df['Cluster'] = customer['value_cluster']\n",
    "\n",
    "# Agrupar e calcular média\n",
    "profile_value = temp_df.groupby('Cluster').mean().T\n",
    "\n",
    "# Desenhar\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(profile_value, center=0.5, annot=True, cmap=\"RdBu_r\", fmt=\".2f\", ax=ax)\n",
    "ax.set_title(\"Perfilagem: Value Clusters (K=4)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "927d4c3d",
   "metadata": {},
   "source": [
    "cols_behave = df_behave.columns.tolist()\n",
    "temp_df_b = customer[cols_behave].copy()\n",
    "temp_df_b['Cluster'] = customer['behavioral_cluster']\n",
    "\n",
    "# Agrupar e calcular média\n",
    "profile_behave = temp_df_b.groupby('Cluster').mean().T\n",
    "\n",
    "# Desenhar\n",
    "fig, ax = plt.subplots(figsize=(8, 8)) # Mais alto porque deve ter mais variáveis\n",
    "sns.heatmap(profile_behave, center=0.5, annot=True, cmap=\"RdBu_r\", fmt=\".2f\", ax=ax)\n",
    "ax.set_title(\"Perfilagem: Behavioral Clusters (K=4)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "76393cc8",
   "metadata": {},
   "source": [
    "### 7.5 Merge clusters using Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "id": "929cf566",
   "metadata": {},
   "source": [
    "df_centroids = customer.groupby(['value_cluster', 'behavioral_cluster'])[fs_metric_features].mean()\n",
    "df_centroids"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0259921",
   "metadata": {},
   "source": [
    "print(f\"\\nCentroids shape: {df_centroids.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c12ef7c7",
   "metadata": {},
   "source": [
    "# Fit hierarchical clustering with distance tracking\n",
    "hclust = AgglomerativeClustering(\n",
    "    linkage='ward',\n",
    "    metric='euclidean',\n",
    "    distance_threshold=0,\n",
    "    n_clusters=None\n",
    ")\n",
    "hclust_labels = hclust.fit_predict(df_centroids)\n",
    "\n",
    "# Build linkage matrix for dendrogram\n",
    "# (Adapted from scikit-learn documentation)\n",
    "counts = np.zeros(hclust.children_.shape[0])\n",
    "n_samples = len(hclust.labels_)\n",
    "\n",
    "for i, merge in enumerate(hclust.children_):\n",
    "    current_count = 0\n",
    "    for child_idx in merge:\n",
    "        if child_idx < n_samples:\n",
    "            current_count += 1 \n",
    "        else:\n",
    "            current_count += counts[child_idx - n_samples]\n",
    "    counts[i] = current_count\n",
    "\n",
    "linkage_matrix = np.column_stack([\n",
    "    hclust.children_,\n",
    "    hclust.distances_,\n",
    "    counts\n",
    "]).astype(float)\n",
    "\n",
    "print(\"Linkage matrix ready for dendrogram!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2360750d",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "y_threshold = 3.0 # Can adjust this!\n",
    "\n",
    "dendrogram(\n",
    "    linkage_matrix,\n",
    "    labels=df_centroids.index,\n",
    "    color_threshold=y_threshold,\n",
    "    above_threshold_color='k'\n",
    ")\n",
    "\n",
    "plt.axhline(y=y_threshold, color='r', linestyle='--', linewidth=2, label=f'Cut ahreshot {y_threshold}')\n",
    "\n",
    "plt.title(f'Hierarchical Clustering on 12 Centroids\\n(Ward Linkage)', fontsize=16)\n",
    "plt.ylabel('Euclidean Distance')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a1f793db",
   "metadata": {},
   "source": [
    "n_final_clusters = 4\n",
    "\n",
    "hclust_final = AgglomerativeClustering(\n",
    "    linkage='ward',\n",
    "    n_clusters=n_final_clusters\n",
    ")\n",
    "hclust_final_labels=hclust_final.fit_predict(df_centroids)\n",
    "hclust_final_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cddb0131",
   "metadata": {},
   "source": [
    "df_centroids['merged_labels'] = hclust_final_labels\n",
    "df_centroids"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "edb667d9",
   "metadata": {},
   "source": [
    "cluster_mapper = df_centroids['merged_labels'].to_dict()\n",
    "cluster_mapper  "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fd8fa06b",
   "metadata": {},
   "source": [
    "customer['merged_labels'] = customer.apply(\n",
    "    lambda row: cluster_mapper[(row['value_cluster'], row['behavioral_cluster'])],\n",
    "    axis=1\n",
    ")\n",
    "customer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7bf3a32e",
   "metadata": {},
   "source": [
    "print(customer['merged_labels'].value_counts().sort_index())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67b1383c",
   "metadata": {},
   "source": [
    "# Quick distinctiveness check (R²)\n",
    "r2_merged = get_rsq(customer, fs_metric_features, 'merged_labels')\n",
    "print(f\"\\nMerged clustering R²: {r2_merged:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "203b0850",
   "metadata": {},
   "source": [
    "## 8. Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d71cf86",
   "metadata": {},
   "source": [
    "#### 8.1 Metric Features"
   ]
  },
  {
   "cell_type": "code",
   "id": "24beb5a9",
   "metadata": {},
   "source": [
    "# Get centroids for ALL segments\n",
    "all_segments = sorted(customer['merged_labels'].unique())\n",
    "df_all_centroids = customer.groupby('merged_labels')[fs_metric_features].mean()\n",
    "\n",
    "# Create figure with 2 subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# LEFT PLOT: Parallel coordinates for all clusters\n",
    "plt.sca(ax1)\n",
    "pd.plotting.parallel_coordinates(\n",
    "    df_all_centroids.reset_index(),\n",
    "    'merged_labels',\n",
    "    color=sns.color_palette('tab10', n_colors=len(all_segments)),\n",
    "    ax=ax1\n",
    ")\n",
    "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=1.5)\n",
    "ax1.set_title('Parallel Coordinates: All Segments', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Standardized Value', fontsize=12)\n",
    "ax1.set_xlabel('Features', fontsize=12)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "ax1.legend(title='Cluster', loc='best', title_fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# RIGHT PLOT: Cluster sizes (ordered by cluster number)\n",
    "cluster_sizes = customer['merged_labels'].value_counts().sort_index()\n",
    "colors = sns.color_palette('tab10', n_colors=len(all_segments))\n",
    "\n",
    "ax2.bar(cluster_sizes.index.astype(str), cluster_sizes.values, color=colors)\n",
    "ax2.set_xlabel('Number of Customers', fontsize=12)\n",
    "ax2.set_ylabel('Cluster', fontsize=12)\n",
    "ax2.set_title('Cluster Sizes', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "755cf658",
   "metadata": {},
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "all_segments = sorted(customer['merged_labels'].unique())\n",
    "df_all_centroids = customer.groupby('merged_labels')[fs_metric_features].mean().T\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 9))\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(\n",
    "    df_all_centroids,\n",
    "    ax=ax1,\n",
    "    cmap=\"YlGnBu\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cbar_kws={\"shrink\": 0.7}\n",
    ")\n",
    "ax1.set_title('Heatmap: All Segments', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Metric Features', fontsize=13)\n",
    "ax1.set_xlabel('Clusters', fontsize=13)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Cluster sizes\n",
    "cluster_sizes = customer['merged_labels'].value_counts().sort_index()\n",
    "colors = sns.color_palette('tab10', n_colors=len(all_segments))\n",
    "\n",
    "sns.barplot(\n",
    "    x=cluster_sizes.index.astype(str),\n",
    "    y=cluster_sizes.values,\n",
    "    palette=colors,\n",
    "    ax=ax2\n",
    ")\n",
    "ax2.set_title('Cluster Sizes', fontsize=16, fontweight='bold')\n",
    "ax2.set_xlabel('Clusters', fontsize=13)\n",
    "ax2.set_ylabel('Number of Customers', fontsize=13)\n",
    "\n",
    "for i, val in enumerate(cluster_sizes.values):\n",
    "    ax2.text(i, val + max(cluster_sizes.values)*0.01, str(val), ha='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3808e287",
   "metadata": {},
   "source": [
    "df_seg_4 = customer[customer[\"merged_labels\"]==1]\n",
    "RFM_counts = (\n",
    "    df_seg_4.groupby(\"RFM_score\").size().reset_index(name=\"count\").sort_values(\"count\",ascending=False)\n",
    ")\n",
    "RFM_counts\n",
    "#customer[\"RFM_score\"].nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6d4b4aab",
   "metadata": {},
   "source": [
    "\n",
    "##### Behavioral and Value-based perspective clusters\n",
    "\n",
    "**Cluster 0: The \"Ghosted Us\" Exes**\n",
    "\n",
    "**Analysis**\n",
    "The defining characteristic of this group is the extremely high **`recency_months` (4.41)** score. This outlier indicates a significant lapse in time since their last interaction. All other engagement metrics (flights, spending) are negatively correlated.\n",
    "\n",
    "> **Business Impact**\n",
    "> These customers are effectively dormant or churned. A final, low-cost re-engagement campaign is recommended, but further investment is likely wasted as they have disengaged from the brand.\n",
    "\n",
    "---\n",
    "\n",
    "**Cluster 1: The \"Economy Class Heroes\"**\n",
    "\n",
    "**Analysis**\n",
    "This is the **largest segment (6,397 customers)**. While their **`Income`** is lower (-0.68) compared to the Elite group, their travel frequency (**`NumFlights`**) and distance metrics are positive and robust. They fly as often as the VIPs but likely on a budget.\n",
    "\n",
    "> **Business Impact**\n",
    "> They provide the essential operational volume for the airline. They are loyal but price-sensitive. The focus should be on volume-based rewards and reliability rather than luxury services.\n",
    "\n",
    "---\n",
    "\n",
    "**Cluster 2: The \"Stay-at-Home\" Club**\n",
    "\n",
    "**Analysis**\n",
    "This group scores negatively across almost all engagement metrics, particularly **`NumFlights` (-1.28)** and **`DistanceKM` (-1.29)**. Despite having average income levels, they simply do not travel with your airline.\n",
    "\n",
    "> **Business Impact**\n",
    "> These are low-yield customers. They do not justify significant marketing spend. They may be seasonal travelers or users who use the program for non-flight partnerships.\n",
    "\n",
    "---\n",
    "\n",
    "**Cluster 3: The \"Free Lunch\" Hunters**\n",
    "\n",
    "**Analysis**\n",
    "A statistical anomaly (only 36 customers), but behaviorally distinct. They show the highest **`PointsUtilizationRate` (1.21)** combined with the lowest **`Tenure` (-1.02)**.\n",
    "\n",
    "> **Business Impact**\n",
    "> These appear to be new users who joined specifically to redeem rewards or exploit a sign-up bonus (\"churning\"). They are cashing out value without contributing to revenue. This segment should be monitored for fraud or policy loopholes.\n",
    "\n",
    "---\n",
    "\n",
    "**Cluster 4: The \"Wolf of Wall Street\" VIPs**\n",
    "\n",
    "**Analysis**\n",
    "This segment represents your high-value customers. They exhibit the highest **`Income` (0.95)** and **`Customer Lifetime Value` (1.06)** scores. Furthermore, they are highly active travelers (high `NumFlights` and `DistanceKM`) with solid loyalty (`Tenure`).\n",
    "\n",
    "> **Business Impact**\n",
    "> These are the primary revenue drivers. The strategy should focus on premium retention, exclusive perks, and high-touch service to prevent churn to competitors.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc833c",
   "metadata": {},
   "source": [
    "#### 8.2 Non Metric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a461e",
   "metadata": {},
   "source": [
    "Here in profile we can see the distribution of the non metric features by cluster, but we can conclude that just education and marital status are relevant to the segments."
   ]
  },
  {
   "cell_type": "code",
   "id": "b7b746e8",
   "metadata": {},
   "source": [
    "for i in Demographic_Segmentation:\n",
    "    pd.crosstab(customer['merged_labels'], customer[i], normalize='index').plot.bar(\n",
    "    stacked=True,\n",
    "    figsize=(10, 6)\n",
    "    )\n",
    "    plt.title(f\"{i} Distribution by Merged Segment\", fontsize=14)\n",
    "    plt.xlabel(\"Merged Segment\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=i, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9aee066b",
   "metadata": {},
   "source": [
    "##### Demographic Deep-Dive: Connecting Behavior to Identity\n",
    "**1. Education is the Strongest Predictor of Value**\n",
    "\n",
    "The distinction between VIPs and the mass market is not just about how much they fly, but their professional background.\n",
    "\n",
    "The Data: The high-value Cluster 4 is almost exclusively composed of holders of a Bachelor's degree. In contrast, the mass-market Cluster 1 has a significant portion of users with \"College\" education.\n",
    "\n",
    "Conclusion: Our most profitable customers are white-collar professionals. This validates the \"Wolf of Wall Street\" persona, these are business travelers whose flights are likely paid for by their companies or supported by higher professional salaries.\n",
    "\n",
    "**2. The \"Cluster 3\" Anomaly: The Montreal Glitch**\n",
    "\n",
    "We previously identified Cluster 3 as the \"Free Lunch Hunters\" (high points use, low loyalty). The demographic data reveals exactly where this happened.\n",
    "\n",
    "The Data: While other clusters are distributed across the country (Toronto, Vancouver, etc.), Cluster 3 is overwhelmingly concentrated in Quebec and specifically Montreal.\n",
    "\n",
    "Conclusion: This suggests the high rate of points churning wasn't a general problem, but likely the result of a specific local campaign, partnership, or loophole in the Quebec market. It’s a regional issue, not a national one.\n",
    "\n",
    "**3. Stability Drives Loyalty**\n",
    "\n",
    "There is a clear correlation between life stability and airline loyalty.\n",
    "\n",
    "The Data: Cluster 4 (VIPs) has the highest proportion of Married customers. Meanwhile, Cluster 3 (The Hunters) has the largest percentage of Single users.\n",
    "\n",
    "Conclusion: Our VIPs are established individuals with families, valuing consistency and comfort. The \"Hunters\" are likely younger, single urbanites (specifically in Montreal) who have the flexibility to chase deals and switch brands aggressively."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Merged Clusters Visualisation",
   "id": "8f7f3cc2f9d25188"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "customer['merged_labels'].value_counts().sort_index()",
   "id": "d7e1ed3c67fb8001"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(fs_metric_features)",
   "id": "673c891e2d8b9e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 9.1. PCA",
   "id": "30860771999d7cdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_result = pca.fit_transform(customer[fs_metric_features])\n",
    "\n",
    "pca_result.shape"
   ],
   "id": "a133548f45b90c74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "customer['pca_1'] = pca_result[:, 0]\n",
    "customer['pca_2'] = pca_result[:, 1]\n",
    "\n",
    "# Variance explained\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"PCA Variance Explained:\")\n",
    "print(f\"  PC1:      {var_explained[0]:.1%}\")\n",
    "print(f\"  PC2:      {var_explained[1]:.1%}\")\n",
    "print(\"=\"*20)\n",
    "print(f\"  Total:    {var_explained.sum():.1%}\")"
   ],
   "id": "e18d8d76f1c8cdb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we are going to see the lossin 2D PCA projection",
   "id": "a3f4e5e35f2f451"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_pca_variance(data=customer,features=fs_metric_features)",
   "id": "5c619ce7822f7c0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_pca_clusters(df=customer,label_col='merged_labels',pc1_col='pca_1',pc2_col='pca_2',var_explained=var_explained,title='2D PCA Projection of 7 Customer Segments')",
   "id": "e5d4b71300e353c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pc_corr = customer[fs_metric_features+['pca_1', 'pca_2']].corr().round(3)\n",
    "pc_corr = pc_corr.loc[fs_metric_features, ['pca_1', 'pca_2']]\n",
    "pc_corr"
   ],
   "id": "5ea20cd3f6221273"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=metric_features\n",
    ")\n",
    "\n",
    "print(\"PCA Component Loadings (Feature Contributions):\\n\")\n",
    "print(loadings.round(3))"
   ],
   "id": "a5fc612caaa6facd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 9.2. t-SNE",
   "id": "f9fb474b397ad1f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "two_dim = TSNE(n_components=2, random_state=42, perplexity=20, n_iter_without_progress=500).fit_transform(customer[fs_metric_features])",
   "id": "98be2661dafd71bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pd.DataFrame(two_dim).plot.scatter(x=0, y=1, c=customer['merged_labels'], colormap='Set2', figsize=(15,10))\n",
    "plt.show()"
   ],
   "id": "4dc483651f7ae021"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "t-SNE with pca",
   "id": "49990a8b5d872b2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "two_dim = TSNE(random_state=42, perplexity=30).fit_transform(pca_result)\n",
    "\n",
    "pd.DataFrame(two_dim).plot.scatter(x=0, y=1, c=customer['merged_labels'], colormap='Set2', figsize=(15,10))\n",
    "plt.show()"
   ],
   "id": "d851410129c0f618"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 9.3. UMAP",
   "id": "3cef9605ce9ef5a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "##todo",
   "id": "3b2e0a960a684493"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
